var store = [{
        "title": "Quanto grande è il mondo di Harry Potter?",
        "excerpt":"Venti anni fa, nel 1998, usciva in Italia “Harry Potter e la Pietra Filosofale”, il primo della serie di romanzi partoriti dalla penna di J. K. Rowling che sarà destinata a cambiare per sempre sia la narrativa young adults che il genere fantasy tout cour. Ammetto di aver scoperto relativamente tardi i volumi; e questo, credo, mi ha permesso di apprezzarli maggiormente e cogliere delle interessanti sfumature.   Affascinato dal mondo incredibilmente immersivo creato dalla Rowling, dalle vicende e dalle relazioni tra i personaggi, mi sono subito chiesto se i personaggi individuassero reti credibili, dal punto di vista sociale, e le loro caratteristiche.   Ebbene, molte tecniche di Social Network Analysis possono essere applicate anche allo opere di letteratura, purché adeguatamente “premasticate”; i risultati sono, come vedremo subito, stimolanti e, talvolta, inaspettati.   Il testo  utilizzato per l’analisi è la versione ePub in lingua inglese, acquistata dal sito ufficiale.   Una prima occhiata a “La pietra Filosofale”   Il primo volume della serie ha più che altro lo scopo di introdurre i personaggi e delinearne i ruoli (l’eroe, il supporto, l’antagonista, eccetera); introduce i personaggi che gravitano attorno alla Scuola di Magia e di Stregoneria di Hogwarts, ma non ne approfondisce le relazioni. Questo non è un problema: ciò che ci interessa, in effetti, non è l’importanza narrativa degli attori, ma le loro conversazioni; solo se i personaggi sono stati coinvolti almeno in una conversazione, infatti, questi potranno dire di avere una reciproca relazione sociale.       Top 15 Personaggi e loro linee di dialogo, in ordine decrescente. Harry è molto presente sin da subito e rivaleggia con Hermione, che arriverà più tardi con la sua proverbiale logorrea.   Dalla lettura delle sequenze dei dialoghi, vediamo immediatamente che il libro si concentra attorno alle vicende del protagonista, Harry; egli è, infatti, presente in quasi tutte le conversazioni. La rete, c’è da aspettarsi, avrà spiccate caratteristiche di una ego-network, forse sarà addirittura una rete (quasi) a stella. Non c’è da stupirsi: tutta la storia si svolge attorno a Harry e tutte le reti sociali espresse hanno nel giovane mago se non il destinatario naturale, almeno uno spettatore privilegiato.   La mia ipotesi di lavoro è stata quella di considerare tutti i personaggi individuati in una conversazione come facenti parte di una clique, ovvero un sottogruppo di individui completamente connesso, senza distinguere tra chi parla e chi ascolta. Questo implica che la rete che verrà individuata sarà non direzionata.   Ho, inoltre, considerato solo gli individui fisicamente presenti nelle “scene”, perché su di essi si basano le relazioni interpersonali tra i personaggi. Personaggi citati, anche più volte, ma mai presenti fisicamente non sono quindi rappresentati. L’esempio più evidente sono i genitori di Harry.   Ho, infine, considerato una rete statica, riservandomi in futuro il divertimento di studiare la dinamica di crescita della rete (magari su tutti e sette i libri della serie).   La rete   Ma bando alle ciance e vediamo, nel concreto, la rete nella sua rappresentazione migliore:        Chiaramente Harry è al centro della rete e forma una clique molto stretta con, come prevedibile, Ron ed Hermione - gli altri due principali protagonisti del romanzo. Anche Hagrid, l’adulto più vicino a Harry all’inizio della saga, gode di una posizione che sembra essere molto privilegiata. Al contrario, personaggi molto importanti nella trama, come Albus Silente, non sono coinvolti in molte conversazioni con Harry e, quindi, assumono una posizione più defilata.   I colori dei nodi individuano i gruppi di affiliazione, ma anche community dai confini ben definiti - segno che la rete è particolarmente clusterizzabile, nonostante l’elevata densità di collegamenti.   Ma possiamo dire qualcosa di più sui ruoli, adesso?       Albus Silente, Dumbledore nel testo originale, è molto importante nella storia, ma non è poi così influente, stando alla sua posizione nella rete.   Ron Weasley, l’eterno secondo…   Sia come sia, quello che salta immediatamente all’occhio nella rete è la sua grande coesione: un solo componente, tutti i personaggi raggiungibili a distanza uno o due - sempre attraverso Harry - e un elevata densità di clique. Ma quali sono i sottogruppi realmente influenti e chi è il vero comprimario di Harry nel romanzo?   Innanzitutto va detto che per quanto Harry sia il fulcro della rete, egli non è un punto di articolazione, ovvero non è un nodo la cui rimozione, da solo, va a provocare la rottura della rete in due (o più) sottoreti. Se trascuriamo Madam Hooch e la Prof.ssa McGonagall (che lo sono, ma a favore di personaggi che sono all’estrema periferia della rete), per disgregare la rete, oltre a Harry è necessario rimuovere almeno uno tra Ron ed Hagrid; ben sei componenti, se a essere rimosso è Hagrid.   In una rete tanto fitta, sembra difficile individuare dei cluster definiti e dei personaggi ben rappresentativi per ognuno. Verrebbe da dire che la ego-rete con Harry al centro, che non ci dimentichiamo è pur sempre il ragazzo-che-è-sopravvissuto, dia poco spazio a comprimari e a una eventuale figura di coesione. Figura che, per la verità, la trama vorrebbe in Ron Weasley, il miglior amico del protagonista, nonché suo eterno e talvolta frustrato secondo.   Ma è davvero così?   Data la natura puramente speculativa dell’esplorazione e la natura artificiosamente bilanciata della rete, per dare una risposta a questa domanda mi limiterò a studiare i k-core, la cui definizione li descrive come i sottogruppi massimali aventi almeno k connessioni con altri elementi del medesimo gruppo. Questo, intanto, ci consente di stimare quantitativamente il grado di coesione locale della rete. Vediamola graficamente e anche in forma tabellare, più sotto.                       k       Individui                       1       3                 2       5                 3       1                 4       7                 5       4                 7       2                 8       15           Harry, Ron, Hermione e altri personaggi, quasi tutti della casa di Grifondoro, appartengono al grosso nucleo con k=8, il più imponente della rete. Un core così massiccio è raro, nelle reti reali, ma non così esotico nella fiction di genere (in cui le relazioni sono semplificate e “velocizzate” per essere più vicine al protagonista di quanto non lo sarebbero mai in realtà). Ma qui è il ruolo di Hagrid che mi interessa: egli è, infatti, nel core k=8, ma non è nello stesso gruppo (Grifondoro) degli altri componenti del nucleo. E’ un importante punto di articolazione della rete, come abbiamo già visto, e di primo acchitto sembra anche assumere una posizione piuttosto importante. Vale la pena di studiarne la centralità (Top 5 personaggi):                  name       degree.std       betweeness.proximal       closeness.std                       Harry Potter       34       260.658333       0.9473684                 Rubeus Hagrid       25       91.130952       0.7500000                 Ron Weasley       22       43.625000       0.7058824                 Hermione Granger       19       35.783333       0.6666667                 Draco Malfoy       13       12.826190       0.6000000                 Quirinus Quirrell       12       9.741667       0.5901639           Tralasciando gli ultimi due personaggi (due antagonisti) e Harry, che naturalmente ha un ruolo di assoluto primato, notiamo che le misure di centralità danno un quadro un po’ diverso da quello che il romanzo ci descrive. Hagrid, in effetti, “vince” su Ron di stretta misura su almeno due misurazioni - che sono quelle più influenzate dal ruolo, predominante, dell’ingombrante vicino “egoico” Harry - ma risulta di gran lunga privilegiato nella Proximal Betweeness Centrality, misura di centralità che favorisce il ruolo dei nodi di intermediazione diretta nelle relazioni prossime.   E’ Hagrid, in definitiva, la vera “spalla” di Harry - in termini di relazioni sociali - ed è sempre lui il personaggio la cui dipartita provocherebbe il più elevato contraccolpo sociale: ha un ruolo fortemente centrale, abilita l’accesso a diverse risorse periferiche della rete, fa parte del nucleo di massima coesione k=8, ma non fa parte di Grifondoro e pertanto è, da essi, meno propenso a esserne influenzato.   Niente male per un guardacaccia, no?       Povero Ron…nella trama del romanzo è l’eterno secondo. Mentre nella topologia della rete è addirittura terzo!   Se siete interessati a come ho costruito la rete a partire da un ebook, vi invito a dare una occhiata al codice sorgente, ampiamente commentato, disponibile su Github. Codice che sarà, io spero, comunque oggetto di un futuro articolo.  ","categories": ["Social Network Analysis"],
        "tags": [],
        "url": "https://gabrielebaldassarre.com/quanto-grande-mondo-harry-potter/",
        "teaser": "https://gabrielebaldassarre.com/assets/images/harry-potter-philosophers-teaser.jpg"
      },{
        "title": "L'importanza degli individui in una rete",
        "excerpt":"Tutti coloro che si approcciano alla Social Network Analysis si aspettano che questa disciplina li aiuti a capire quali sono gli individui più prominenti in una data rete sociale. Una richiesta più che ovvia, dato che la SNA per definizione studia le relazioni tra gli attori proprio con questa finalità. Gli strumenti a disposizione per rispondere a domande di questo tipo sono moltissimi: alcuni sono semplici, altri estremamente sofisticati; tutti molto utili, in effetti. Ma prima di addentrarci nello specifico bisogna porsi una domanda fondamentale: cosa intendiamo per prominenza in una rete sociale?   Prestigio, centralità, capacità di influenzare   La domanda, forse ci siete arrivati, è palesemente faziosa. Si può parlare di prominenza come la capacità di un attore di essere estremamente coinvolto in relazioni con gli altri attori della rete, ma è una definizione fine a se stessa.   La verità è che non esiste un concetto unico di prominenza né un’unica modalità per isolare i nodi “importanti” in una rete; la misura è, piuttosto, contestuale alla funzione che ci aspettiamo dagli attori stessi e al volume e il tipo di informazioni a cui essi hanno accesso e di cui abbiamo bisogno.      Siamo interessati ai nodi che sono in grado meglio di altri di trasferire un’informazione? In tal caso, cerchiamo i nodi che siano al centro della rete (a vario titolo).   Vogliamo isolare i nodi che siano percepiti come punto di riferimento della rete? Allora forse siamo interessati al prestigio.   Ci interessa coinvolgere i nodi chiave che più di altri possono influenzare, con le loro scelte, ampie zone della rete? Probabilmente quello che ci serve è il brokeraggio.   …   La lista potrebbe continuare per un bel po’ perché pressoché infiniti sono i modelli interpretativi che possiamo costruire sopra una rete sociale. Come insegna il   costruzionismo, la nostra interpretazione della realtà sociale crea dei modelli. E questi modelli possono essere analizzati e le loro proprietà misurate.   Ma torniamo alla lista; per cominciare, perché è il problema più semplice, ma comunque ricchissimo di applicazioni pratiche, in questo articolo affronteremo il primo punto: quello della misura della centralità.   Nel concreto, andremo a introdurre tre misure per altrettante tipologie di centralità e lo faremo, a titolo d’esempio, su alcune reti “giocattolo”, come quella qui sotto.        Essere il più attivo di tutti: Degree Centrality   La definizione più semplice possibile di centralità è quella per cui l’attore centrale è, molto semplicemente, il più attivo di tutti all’interno di una rete, ovvero colui il quale ha il maggior numero di collegamenti da e verso altri nodi. Questa è la Degree Centrality che, come è intuibile, può essere applicata sia a reti non direazionate che a reti direzionate (in questo caso le misure diventano due: In-Degree Centrality e Out-Degree Centrality).   L’interpretazione della misura è molto semplice: gli individui con elevata degree centrality sono quelli che si trovano vicini all’azione e sono quelli che godono della maggiore visibilità, nonché accesso al maggior quantitativo di risorse, perché il numero di contatti a cui possono attingere è più alto.   Vediamolo visualmente nella nostra rete giocattolo, dove la dimensione dei nodi è qui proporzionale al valore di Degree Centrality (In+Out). Si vede subito la prominenza, in termini di connessioni, dei nodi 4, 14 e 20: i nodi più visibili della rete.        Ora, la misura è semplice e l’interpretazione immediata, ma contare semplicemente i collegamenti non fa, di per sé, un nodo importante. In particolare, questa misura non dice nulla circa il tipo dei collegamenti, una cosa che non va trascurata. Rimedieremo subito.   Essere fondamentale: Betweeness Centrality   Talvolta un nodo può risultare importante anche quando non ha un elevato numero di nodi da e verso di esso. Vediamo per esempio la rete qui sotto, in cui i numeri nei nodi rappresentano la degree centrality:                     A valori alti di degree centrality (i numeri all’interno dei nodi) non necessariamente corrispondono i nodi più importanti di una rete.            A buon senso, è abbastanza evidente che il nodo rosso è essenziale per la tenuta della rete anche se la sua degree centrality è più bassa rispetto a quella dei nodi verdi. Il fatto è che le interazione tra gli individui in una rete non dipendono esclusivamente dai loro vicini più prossimi. Interazioni tra due nodi non adiacenti possono essere influenzate da altri attori della rete, soprattutto se questi giacciono nei possibili percorsi tra i due e possono quindi “metterci il becco”. Questi attori hanno, potenzialmente la possibilità di esercitare un controllo sulla comunicazione proprio in virtù del fatto che, affinché la comunicazione sia possibile, è necessario il loro intervento. In altre parole sono fondamentali per la comunicazione.   Come sappiamo, in una rete i percorsi possibili tra gli individui che la compongono sono infiniti. E sappiamo anche la legge del telefono senza fili: quanto più un percorso è lungo, tanto più l’informazione che giungerà a destinazione sarà distorta (e non è detto che arrivi). Bisogna tenerne conto.   Ebbene, la Betweeness Centrality di un nodo fa esattamente questo: dato un nodo \\( A \\) e prese tutte le coppie possibili di nodi della rete, escluso il nodo \\( A \\) stesso, la betweeness centrality di \\( A \\) è il numero di tutti i percorsi minimi che vi passano attraverso.       Il nodo rosso è un passaggio obbligato per tutti i percorsi che vogliano transitare da un lato all’altro della rete, mentre nessun percorso minimo ha bisogno dei nodi azzurri. Tanto più spesso un nodo si trova a giacere su un percorso minimo che collega coppie qualsiasi di altri nodi della rete, tanto più la sua betweeness centrality sarà alta.   Certo, il nodo rosso si trova in una situazione di forte stress, perché è un nodo che “tiene insieme” la rete (in questi casi si dice che il nodo ha forti costrizioni sociali, lo vedremo in uno dei prossimi articoli), ma il rovescio della medaglia è la situazione di relativa preminenza di cui gode: come anticipavamo, esso è un connettore fondamentale.   Come per il caso precedente, in caso di grafi direzionati avremo a disposizione due misure: la Directed Betweeness Centrality, che tiene conto del verso dei collegamenti per il calcolo dei percorsi minimi, e la Undirected Betweeness Centrality che, invece, li ignora.   Esprimendo con la dimensione dei nodi la betweeness centrality alla nostra rete giocattolo, questo è il risultato:        Si nota subito come, in particolare, il nodo 14, rispetto al calcolo precedente, ora abbia una prominenza maggiore in termini di betweeness; questo grazie alla sua funzione di connessione per la sottorete verde. Questo mentre gli altri nodi rossi, che pure avevano una degree piuttosto prominente, siano praticamente spariti; il loro ruolo di mediatori è vanificato dalla connessione diretta tra il nodo 14 e il nodo 20, più breve, e la loro betweeness ne è risultata compromessa.   Essere efficiente: Closeness Centrality   Supponiamo il caso in cui siamo interessati a individuare i nodi in una rete che hanno più probabilità di reagire prontamente a un dato evento. Più che alla quantità di connessioni o alla capacità di essere fondamentali, in situazioni come queste ci interessa, probabilmente, una misura che tenga conto della distanza: vogliamo che il nostro telefono senza fili non abbia tanti intermediari; vogliamo essere al centro della scena.   Per farlo, ci serviamo della Closeness Centrality. L’idea di base è questa: tanto più tali attori sono vicini a tutti gli altri, tanto più reattivi essi saranno perché minore sarà il numero di mediatori di cui avranno bisogno per trasferire un’informazione da un punto all’altro. In senso più generale, essi sono i nodi più efficienti del flusso di comunicazione della rete (in gergo di comunicazione si parla di reach).   La closeness centrality misura questo concetto; è funzione, come dicevamo, della distanza tra nodi e più nello specifico dato \\( A \\) il nodo di cui si vuole calcolare la closeness, essa è definita come l’inverso delle somma delle distanze tra il nodo \\( A \\) e, ad uno ad uno, tutti gli altri nodi della rete. Questo purché tra i due nodi ci sia un percorso possibile, ovvero fanno parte dello stesso grafo connesso. In caso contrario, la distanza tra i due è infinita e il suo contributo alla closeness (l’inverso) è zero.   Data l’importanza che ricopre, il nodo di un grafo (o di un sottografo) con la closeness centrality più alta viene chiamato centro del grafo (sottografo) o, più spesso, centroide.   Illustriamo meglio il concetto con un paio di esempi di reti illustrative.       Il nodo rosso è un passaggio obbligato per tutti i percorsi che vogliano transitare da un lato all’altro della rete, mentre nessun percorso minimo ha bisogno dei nodi azzurri. Tanto più spesso un nodo si trova a giacere su un percorso minimo che collega coppie qualsiasi di altri nodi della rete, tanto più la sua betweeness centrality sarà alta.   Visualizziamo, per finire, la nostra rete giocattolo, da cui ci accorgiamo di un’altra importante caratteristica della misura: dipende moltissimo dalla topologia della rete. In questo caso specifico, infatti, notiamo subito che più che stravolgere la nostra idea sugli hub ci “riabilita”, paradossalmente, alcuni nodi periferici (azzurri, in basso) che hanno la fortuna di essere connessi a un grande hub. Ma ne parleremo meglio quando approfondiremo lo studio della eccentricità e la eigenvector centrality.        Conclusioni e possibili interpretazioni pratiche   La centralità è un elemento fondamentale dello studio delle reti. Oltre ad essere, nella maggior parte dei casi, rapida e facile da calcolare, ci fornisce contemporaneamente informazioni sulla struttura della rete (sia locale che globale) che sul ruolo degli attori stessi. Come visto, esistono diverse misure della centralità in base al modello di status sociale che ci interessa studiare per i nodi della rete - altre misure più sofisticate saranno oggetto di ulteriori articoli di approfondimento.   Ma come usiamo e interpretiamo nella pratica la centralità? Non esiste una lista di do and don’t, ma questo specchietto di ipotetiche “domande” possono, probabilmente, essere risolte studiando la centralità. Prendete questa tabella cum grano salis mi raccomando, in quanto si tratta solo di spunti di riflessione per spingervi a ragionare sulla centralità e non ha certamente pretesa di essere esaustiva.   Il senso di questa tabella è provate.   Modellate una rete, definite il significato dei collegamenti tra i nodi. senza timore che tali relazioni possano sembrare eccentriche all’inizio, e misurate la centralità.   Se siete fortunati, queste misure vi diranno già tanto sui ruoli prominenti della rete. Ma anche se ciò non fosse, avrete raccolto informazioni preziose sulla rete e sulla credibilità del vostro modello e vi suggerirà se vale la pena continuare lo studio della rete o se dovete rivedere le vostre ipotesi.   La centralità, da questo punto di vista, è un vero coltellino svizzero.                  Misura di Centralità       Interpretazione       Possibile Quesito                       Degree       Nodi raggiungibili direttamente       Nella rete degli impresari musicali, chi di essi darà maggiori garanzie di riempire il cartellone di un evento?                 Betweeness       Nodi che fungono da mediatori       In una rete di spie, attraverso quale di esse passerà il maggior numero di informazioni?                 Closeness       Nodi “rapidi” e/o efficienti       In una rete di relazioni sessuali, quanto velocemente si diffonderà una epidemia a partire dal paziente zero?          ","categories": ["Social Network Analysis"],
        "tags": [],
        "url": "https://gabrielebaldassarre.com/importanza-individui-rete-centralita/",
        "teaser": "https://gabrielebaldassarre.com/assets/images/default-post-teaser.png"
      },{
        "title": "Approfondimento matematico: autovettori e autovalori",
        "excerpt":"```{r setup, include = FALSE} if (!require(\"pacman\")) install.packages(\"pacman\"); invisible(library(pacman)) tryCatch({   p_load(\"tidyverse\") }, warning=function(w){   stop(conditionMessage(w)) })  vectors.plot     Esempio di trasformazione. La matrice \\( A = \\begin{bmatrix} 2 &amp; 1 \\\\ 1 &amp; 2 \\end{bmatrix} \\) produce gli autovettori \\( v_1= \\begin{pmatrix} 1 &amp; 1 \\end{pmatrix}^T \\) e \\( v_2= \\begin{pmatrix} 1 &amp; -1 \\end{pmatrix}^T \\) nelle direzioni rappresentate rispettivamente dalla retta blu e violetto. Tutti i vettori blu, paralleli alla direzione individuata da \\( v_1 \\) sono autovettori perché, quando trasformati attraverso \\( A \\), individuano un vettore con la stessa direzione, ma con un modulo moltiplicato per l’autovalore \\( \\lambda_1=3 \\). Allo stesso modo, i vettori viola sono autovettori con autovalore \\( \\lambda_2 = 1 \\). I vettori rossi, invece, quando trasformati da \\( A \\), variano in direzione: essi non sono autovettori (fonte: Wikipedia).   ## Come calcolare gli autovettori e gli autovalori  Per il calcolo degli autovalori, e quindi degli autovettori, procediamo algebricamente a partire da:  $$ A\\vec{v} = \\lambda\\vec{v} \\tag{1} $$  che equivale a scrivere  $$ \\vec{v}(A - \\lambda I) = 0 \\tag{2} $$  La relazione (2) produce un sistema di equazioni lineari _omogeneo_ ovvero privo del termine noto. Il che significa che è possibile trovare soluzioni non nulle del vettore \\\\( \\vec{v} \\\\) solo se il determinante della matrice che moltiplica \\\\( \\vec{v} \\\\) è zero. In simboli:  $$ \\bbox[5px,border:1px solid red]{ det(A - \\lambda I) = 0 } $$  che, una volta risolto, ci consente di individuare gli autovalori \\\\( \\lambda_{1 \\cdots N} \\\\) e i corrispettivi autovettori.  ## Diagonalizzazione e cambio di sistema di riferimento  Come dicevamo, gli autovettori ricoprono un ruolo essenziale in tanti campi del sapere, dalle scienze delle costruzioni alla meccanica quantistica, dall'elettromagnetismo alla teoria dell'informazione, fino allo studio delle reti.  Alla base di tanta importanza è soprattutto la proprietà degli autovettori di poter trasformare una matrice  \\\\( A \\\\) nella sua corrispettiva __diagonalizzata__, a seguito di un cambio di sistema di riferimento a favore di uno i cui assi siano gli autovettori della matrice stessa. Vediamo praticamente.  Innanzitutto verifichiamo una proprietà molto interessante delle matrici diagonali: quando un vettore \\\\( a \\\\) è _moltiplicato_ per una matrice diagonale \\\\( A \\\\), il vettore risultante \\\\( b \\\\) avrà componenti pari alla proiezione delle componenti del vettore originario sul sistema di assi __ortogonali__ di riferimento moltiplicato scalarmente per i coefficienti sulla diagonale A. Facciamo un esempio.  Supponendo di voler calcolare \\\\( \\vec{b} = A\\vec{a} \\\\) dati:  $$ \\vec{a} = \\begin{pmatrix} 1 \\\\\\\\ 3 \\end{pmatrix}  A = \\begin{bmatrix} 3 & 0 \\\\\\\\ 0 & -2 \\end{bmatrix} $$  Avremo:  $$ \\vec{b} = \\begin{pmatrix} 1 \\\\\\\\ 3 \\end{pmatrix} \\begin{bmatrix} 3 & 0 \\\\\\\\ 0 & -2 \\end{bmatrix} = \\begin{pmatrix} 3 \\\\\\\\ -6 \\end{pmatrix}  $$  ovvero le componenti \\\\(b_x = 3 \\\\) e \\\\(b_y = -6 \\\\) sono le proiezioni sugli assi \\\\( (x, y) \\\\) del vettore \\\\( \\vec{b} \\\\) con un modulo pari alle proiezioni del vettore di partenza \\\\( \\vec{a} \\\\) moltiplicati, come abbiamo già detto, per i coefficienti sulla diagonale \\\\( A \\\\).  ```{r vectors.dotproduct, fig.asp= .6, warning= FALSE} a <- c(1,3) m <- matrix(c(3, 0, 0, -2), 2, 2)  vectors.plot(a, m)  ```  Questo ragionamento è sorprendentemente simile a quanto abbiamo già detto sugli autovettori, ovvero i vettori caratteristici di una trasformazione che individuano delle direzioni sulle quali giacciono i vettori trasformati modificati al più in modulo e verso da un fattore \\\\( \\lambda \\\\)  In altri termini, è possibile rappresentare il vettore \\\\( \\vec{a} \\\\) non più con il sistema di assi \\\\( (x, y) \\\\) ma su un nuovo sistema di assi \\\\( (v_1, v_2) \\\\) costruito sulle direzioni degli autovettori della matrice \\\\( A \\\\). Questo vettore trasformato \\\\( \\vec{a}' \\\\) avrà, come sappiamo, componenti di lunghezza pari a quelle del vettore di partenza \\\\( \\vec{a} \\\\) moltiplicato per i vari autovalori \\\\( \\lambda_N \\\\). In generale queste proiezioni saranno __non ortogonali__, laddove non lo sia stata la matrice di trasformazione di partenza.  Questo ci consente di affermare due cose.  Innanzitutto ci consente di dire che possiamo utilizzare gli autovettori come assi di riferimento per applicare una trasformazione \\\\( A \\\\) a un vettore \\\\( \\vec{a} \\\\), utilizzando gli autovalori \\\\( \\lambda_N \\\\) come moltiplicatori delle componenti di \\\\( \\vec{a} \\\\) sulle direzioni degli autovettori.  Ma quel che è più importante, ci consente di calcolare le coordinate del vettore \\\\( \\vec{a} \\\\) nel nuovo sistema di riferimento individuato dagli autovettori \\\\( (v_1, v_2) \\\\). Vediamo come.  Ricordando che il vettore \\\\( \\vec{a} \\\\) è scomponibile nelle due componenti nelle direzioni degli autovettori, supponendo \\\\( \\vec{v_1} \\\\) e \\\\( \\vec{v_2} \\\\) autovettori __normalizzati__ (cioè con modulo pari a uno), possiamo scrivere questa combinazione lineare:  $$ a = \\alpha v_1 + \\beta v_2 $$  che individua un sistema di equazioni lineari che può essere risolto in \\\\( (\\alpha, \\beta) \\\\) così:  $$ \\begin{pmatrix} a_x \\\\\\\\ a_y \\end{pmatrix} = \\alpha\\begin{pmatrix} v_1x \\\\\\\\ v_1y \\end{pmatrix} + \\beta\\begin{pmatrix} v_2x \\\\\\\\ v_2y \\end{pmatrix} \\Rightarrow $$  $$ \\begin{pmatrix} a_x \\\\\\\\ a_y \\end{pmatrix} = \\begin{pmatrix} \\alpha v_1x + \\beta v_2x \\\\\\\\ \\alpha v_1y + \\beta v_2y \\end{pmatrix} \\Rightarrow $$  $$ \\begin{pmatrix} a_x \\\\\\\\ a_y \\end{pmatrix} = \\bbox[5px,border:1px solid red]{\\begin{pmatrix} v_1x && v_2x \\\\\\\\ v_1y && v_2y \\end{pmatrix}}\\begin{pmatrix} \\alpha \\\\\\\\ \\beta \\end{pmatrix}  $$  Dove la matrice nel riquadro rosso non è altro che la __matrice che ha come colonne le componenti normalizzate degli autovettori della matrice di partenza__ mentre \\\\( (\\alpha, \\beta)^T \\\\) è niente altro che __la rappresentazione del vettore di partenza \\\\(\\vec{a} \\\\) nel nuovo sistema di riferimento dato dagli autovettori__.  Se indichiamo la matrice degli autovettori con \\\\( V \\\\) possiamo in definitiva scrivere:  $$ \\vec{a} = V\\begin{pmatrix} \\alpha \\\\\\\\ \\beta \\end{pmatrix} $$  ovvero  $$  \\begin{pmatrix} \\alpha \\\\\\\\ \\beta \\end{pmatrix} = V^{-1}A $$  Il nuovo sistema di assi così individuato non sarà necessariamente rappresentato da autovettori ortogonali. Tuttavia, questi potranno essere _ortogonalizzati_ facendoli ruotare relativamente uno agli altri in modo da ottenere variazioni di angoli di, giustappunto, 90°.  L'applicazione più concreta del cambio di assi verso un sistema individuato dagli autovettori è proprio nella diagonalizzazione delle matrici che, come detto, ha diversi vantaggi tra cui la semplificazione dei calcoli. Ebbene, possiamo dimostrare che __per diagonalizzare una matrice si possono usare gli autovalori per produrre una base di riferimento ortogonale__. Se gli autovettori sono ortogonali, il vettore trasformato manterrà, nel nuovo sistema di riferimento, la stessa lunghezza - e questa è certamente la situazione più auspicabile. In caso contrario, il vettore trasformato presenterà una lunghezza diversa.  Ma vediamo come. Ricordando l'equazione fondamentale degli autovettori per cui in uno spazio a \\\\( N \\\\) dimensioni abbiamo al più \\\\( N \\\\) autovettori e autovalori e la cui espressione del k-esimo è la seguente:  $$ A\\vec{v_k} = \\lambda_k\\vec{v_k} \\text{  con   } k = 1,\\ldots,N $$  Ovvero  $$ \\begin{matrix} A\\vec{v_1} = \\lambda_1\\vec{v_1} \\\\\\\\ A\\vec{v_2} = \\lambda_2\\vec{v_2} \\\\\\\\ \\vdots \\\\\\\\ A\\vec{v_k} = \\lambda_k\\vec{v_k} \\end{matrix} \\Rightarrow $$  $$ A(v_1 v_2 \\ldots v_N) = (v_1 v_2 \\ldots v_N)\\Lambda $$  con i vettori \\\\( v_k \\\\) gli autovettori e \\\\( \\Lambda \\\\) la __matrice degli autovalori__ che, infatti, vale:  $$ \\Lambda = \\begin{pmatrix} \\lambda_1 & 0 & \\ldots & 0 \\\\\\\\ 0 & \\lambda_2 & \\ldots & 0 \\\\\\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\\\\\ 0 & 0 & \\ldots & \\lambda_k \\end{pmatrix} $$  che, come si può vedere, è una matrice che presenta sulla diagonale principale i coefficienti degli autovalori della matrice \\\\( A \\\\).  Per finire, andando a indicare con \\\\( V \\\\) la matrice degli autovettori utilizzati precedentemente, otterremo l'equazione fondamentale per la diagonalizzazione di una matrice:  $$ \\bbox[5px,border:1px solid red]{ VA = V\\Lambda } $$  In altri termini, __la matrice degli autovalori \\\\( \\Lambda \\\\) sarà la rappresentazione diagonale della matrice \\\\( A \\\\) in un sistema di riferimento individuato dagli autovettori di \\\\( A \\\\)__, o come si dice più propriamente _nell'autospazio di \\\\( A \\\\)_.  Ma a cosa serve tutto ciò?  ## Una applicazione pratica: la compressione dell'informazione Sia data una certa matrice quadrata \\\\( A \\\\). La __matrice degli autovettori__ esprime la __varianza__ di \\\\(A \\\\), ovvero _le informazioni che contiene_. Il quantitativo di varianza espressa da ogni singolo autovettore è espresso dal valore dell'autovettore corrispondente. Vediamolo con un esempio con la seguente matrice \\\\( A \\\\):  ```{r eigen.example, include = FALSE} eigen.example.values <- c(2,-1,3,3,-2,2,15,-9,16) eigen.mat <- matrix(eigen.example.values, nrow = 3, byrow = T) ev <- eigen(eigen.mat) ``` $$ A = \\begin{pmatrix} 2 & -1 & 3 \\\\\\\\ 3 & -2 & 2  \\\\\\\\ 15 & -9 & 16 \\end{pmatrix}   $$  (si noti che la matrice A è di ordine 3 con il terzo componente volutamente molto _vicino_ ma non coincidente alla combinazione lineare \\\\( 3a_1 + 3a_2\\\\)).  Ora calcoliamo gli autovalori e gli autovettori corrispondenti:  $$ \\begin{matrix} \\lambda_1 = `r format(ev$values[1], digits = 2, nsmall = 2)` \\\\\\\\ \\lambda_2 = `r format(ev$values[2], digits = 2, nsmall = 2)` \\\\\\\\ \\lambda_3 = `r format(ev$values[3], digits = 2, nsmall = 2)` \\end{matrix} $$  $$ V = \\begin{pmatrix} -0.18 & 0.26 & -0.64 \\\\\\\\ -0.12 & -0.68 & -0.19 \\\\\\\\ -0.97 & -0.68 & 0.74 \\end{pmatrix} $$  $$ V^-1 = \\begin{pmatrix} -0.81 & 0.47 & -0.93 \\\\\\\\ 1.04 & -0.86 & -0.08 \\\\\\\\ -0.80 & -0.60 & 0.22 \\end{pmatrix} $$  Notiamo subito che \\\\( \\lambda_3 \\\\) è molto più piccolo in modulo degli altri due autovalori. Questo significa che il suo contributo all'informazione contenuta in \\\\( A \\\\) è molto ridotto, rispetto agli altri due.  Decidiamo allora di _scartarlo_ e di scartare anche l'autovettore corrispondente.  $$ \\Lambda = \\begin{pmatrix} 17.5 & 0 \\\\\\\\ 0 & -1.6 \\end{pmatrix} $$  $$ V = \\begin{pmatrix} -0.18 & 0.26 4 \\\\\\\\ -0.12 & -0.68  \\\\\\\\ -0.97 & -0.68  \\end{pmatrix} $$  $$ V^-1 = \\begin{pmatrix} -0.81 & 0.47 & -0.93 \\\\\\\\ 1.04 & -0.86 & -0.08  \\end{pmatrix} $$   Ora, dalla formula della diagonalizzazione abbiamo che  $$ A = V\\Lambda V^{-1} $$  e facendo i calcoli abbiamo questa rappresentazione di \\\\( A \\\\) che per distinguerla dall'originaria decoro con un pedice \\\\( R \\\\):  $$ A_R = \\begin{pmatrix} 1.98 & -1.01 & 3 \\\\\\\\ 2.97 & -2.01 & 2  \\\\\\\\ 15 & -8.99 & 15.99 \\end{pmatrix}  $$  che non è _identica_ alla matrice \\\\( A \\\\), ma è senza dubbio _estremamente_ simile ad essa. Ma ottenuta lavorando con matrici di dimensione 2 invece di 3, ovvero con _meno calcoli_.  Abbiamo, nel concreto, ricostruito la matrice \\\\( A \\\\) utilizzando una sua espressione diagonale valutata su una base di autovettori _ridotta_ rispetto a quella individuabile da \\\\( A \\\\) e nel farlo abbiamo perso un quantitativo _trascurabile_ di informazione.  Geometricamente, abbiamo espresso \\\\( A_R \\\\) in un sistema di riferimento avente un numero di dimensioni più basso rispetto all'ordine di \\\\( A \\\\).  Nella pratica, abbiamo condotto una operazione di __compressione dell'informazione__.  ## Autovettori e Social Network Analysis  L'importanza degli autovettori per la scienza dell'informazione, come potete immaginare, già solo per la capacità di ridurre di dimensioni un sistema è estrema. Ma come possiamo applicare questo potente strumento allo studio delle reti sociali?  Per rispondere a questa domanda basta ricordare che noi possiamo __sempre__ esprimere una rete di relazioni attraverso la _matrice delle adiacenze_. E questa matrice è, tipicamente, _non singolare_ quindi ammette un'inversa e, quindi, _su di essa è possibile calcolare gli autovalori e gli autovettori_.  Lo vedremo presto su una particolare misura di centralità, chiamata __Eigenvector Centrality__, sulla quale si è molto parlato negli ultimi anni e ancora di più se ne parlerà in futuro.  E' la modalità, infatti, su cui Google ha costruito il suo famigerato algoritmo _PageRank_, per stimare l'autorevolezza e ordinare i link nei risultati del motore di ricerca.  Esatto, Google. E parte tutto da qui. ","categories": ["Matematica"],
        "tags": [],
        "url": "https://gabrielebaldassarre.com/introduzione-autovettori-autovalori/",
        "teaser": "https://gabrielebaldassarre.com/assets/images/eigenvectors-teaser.jpg"
      },{
        "title": "Approfondimento matematico: autovettori e autovalori",
        "excerpt":"Lo studio degli autovettori e dei corrispondenti autovalori è un qualcosa in cui ci siamo cimentati probabilmente tutti almeno una volta nella vita. In pochi, tuttavia, sanno che questo strumento è di importanza vitale sia per la Social Network Analysis che per la Fisica Quantistica. Nel primo caso, per via di tutto ciò che concerne la centralità.   Senza la pretesa di fornire una trattazione rigorosa sull’argomento come se dovessimo preparare un esame di algebra lineare, qui ci concentreremo sull’intuizione dei concetti fondamentali così da avere tutti le conoscenze necessarie per utilizzarli in ambito di analisi delle reti sociali.   Autovettori e autovalori: una definizione informale   Supponiamo di avere una matrice di trasformazione quadrata \\( A \\). Essa può essere vista come un operatore perché può essere applicata (mediante prodotto scalare) a un vettore \\( \\vec{x} \\) al fine di ottenere un vettore \\( \\vec{y} \\), ovvero:   \\[A\\vec{x} = \\vec{y}\\]  Per chi non ha paura di fare indigestione di algebra lineare possiamo aggiungere che la matrice \\( A \\) è un endomorfismo.   Ebbene, gli autovettori sono quei vettori che giacciono su delle direzioni caratteristiche della trasformazione \\( A \\) tali per cui quando sono moltiplicati per \\(A \\) danno come risultato altrettanti vettori non nulli che si differenziano dai vettori di partenza al più per il modulo e per il verso, mentre le loro direzioni restano invariate.   In altri termini, supponendo che \\( A \\) sia una matrice \\( 2 \\times 2 \\) di righe linearmente indipendenti, ovvero un endomorfismo in \\( \\mathbb{R}^2 \\), allora esiste qualche coppia \\( (x, y) \\ne (0, 0) \\) che, trasformata mediante \\( A \\), dia come risultato ancora la coppia \\( (x, y) \\) moltiplicata per \\( \\lambda \\), che ne modifica il modulo e, eventualmente, il verso ovvero:   \\[A(x, y) = \\lambda(x, y)\\]  I rispettivi coefficienti \\( \\lambda \\) degli autovettori prendono il nome di autovalori. In caso di \\( \\lambda \\) positivo, il rispettivo vettore trasformato non subisce un cambiamento di verso; quando negativo, il verso ne risulterà opposto. Ma, sia come sia, la direzione individuata dagli autovettori non cambia.       Esempio di trasformazione. La matrice \\( A = \\begin{bmatrix} 2 &amp; 1 \\\\ 1 &amp; 2 \\end{bmatrix} \\) produce gli autovettori \\( v_1= \\begin{pmatrix} 1 &amp; 1 \\end{pmatrix}^T \\) e \\( v_2= \\begin{pmatrix} 1 &amp; -1 \\end{pmatrix}^T \\) nelle direzioni rappresentate rispettivamente dalla retta blu e violetto. Tutti i vettori blu, paralleli alla direzione individuata da \\( v_1 \\) sono autovettori perché, quando trasformati attraverso \\( A \\), individuano un vettore con la stessa direzione, ma con un modulo moltiplicato per l’autovalore \\( \\lambda_1=3 \\). Allo stesso modo, i vettori viola sono autovettori con autovalore \\( \\lambda_2 = 1 \\). I vettori rossi, invece, quando trasformati da \\( A \\), variano in direzione: essi non sono autovettori (fonte: Wikipedia).   Come calcolare gli autovettori e gli autovalori   Per il calcolo degli autovalori, e quindi degli autovettori, procediamo algebricamente a partire da:   \\[A\\vec{v} = \\lambda\\vec{v} \\tag{1}\\]  che equivale a scrivere   \\[\\vec{v}(A - \\lambda I) = 0 \\tag{2}\\]  La relazione (2) produce un sistema di equazioni lineari omogeneo ovvero privo del termine noto. Il che significa che è possibile trovare soluzioni non nulle del vettore \\( \\vec{v} \\) solo se il determinante della matrice che moltiplica \\( \\vec{v} \\) è zero. In simboli:   \\[\\bbox[5px,border:1px solid red]{ det(A - \\lambda I) = 0 }\\]  che, una volta risolto, ci consente di individuare gli autovalori \\( \\lambda_{1 \\cdots N} \\) e i corrispettivi autovettori.   Diagonalizzazione e cambio di sistema di riferimento   Come dicevamo, gli autovettori ricoprono un ruolo essenziale in tanti campi del sapere, dalle scienze delle costruzioni alla meccanica quantistica, dall’elettromagnetismo alla teoria dell’informazione, fino allo studio delle reti.   Alla base di tanta importanza è soprattutto la proprietà degli autovettori di poter trasformare una matrice  \\( A \\) nella sua corrispettiva diagonalizzata, a seguito di un cambio di sistema di riferimento a favore di uno i cui assi siano gli autovettori della matrice stessa. Vediamo praticamente.   Innanzitutto verifichiamo una proprietà molto interessante delle matrici diagonali: quando un vettore \\( a \\) è moltiplicato per una matrice diagonale \\( A \\), il vettore risultante \\( b \\) avrà componenti pari alla proiezione delle componenti del vettore originario sul sistema di assi ortogonali di riferimento moltiplicato scalarmente per i coefficienti sulla diagonale A. Facciamo un esempio.   Supponendo di voler calcolare \\( \\vec{b} = A\\vec{a} \\) dati:   \\[\\vec{a} = \\begin{pmatrix} 1 \\\\\\\\ 3 \\end{pmatrix}  A = \\begin{bmatrix} 3 &amp; 0 \\\\\\\\ 0 &amp; -2 \\end{bmatrix}\\]  Avremo:   \\[\\vec{b} = \\begin{pmatrix} 1 \\\\\\\\ 3 \\end{pmatrix} \\begin{bmatrix} 3 &amp; 0 \\\\\\\\ 0 &amp; -2 \\end{bmatrix} = \\begin{pmatrix} 3 \\\\\\\\ -6 \\end{pmatrix}\\]  ovvero le componenti \\(b_x = 3 \\) e \\(b_y = -6 \\) sono le proiezioni sugli assi \\( (x, y) \\) del vettore \\( \\vec{b} \\) con un modulo pari alle proiezioni del vettore di partenza \\( \\vec{a} \\) moltiplicati, come abbiamo già detto, per i coefficienti sulla diagonale \\( A \\).      Questo ragionamento è sorprendentemente simile a quanto abbiamo già detto sugli autovettori, ovvero i vettori caratteristici di una trasformazione che individuano delle direzioni sulle quali giacciono i vettori trasformati modificati al più in modulo e verso da un fattore \\( \\lambda \\)   In altri termini, è possibile rappresentare il vettore \\( \\vec{a} \\) non più con il sistema di assi \\( (x, y) \\) ma su un nuovo sistema di assi \\( (v_1, v_2) \\) costruito sulle direzioni degli autovettori della matrice \\( A \\). Questo vettore trasformato \\( \\vec{a}’ \\) avrà, come sappiamo, componenti di lunghezza pari a quelle del vettore di partenza \\( \\vec{a} \\) moltiplicato per i vari autovalori \\( \\lambda_N \\). In generale queste proiezioni saranno non ortogonali, laddove non lo sia stata la matrice di trasformazione di partenza.   Questo ci consente di affermare due cose.   Innanzitutto ci consente di dire che possiamo utilizzare gli autovettori come assi di riferimento per applicare una trasformazione \\( A \\) a un vettore \\( \\vec{a} \\), utilizzando gli autovalori \\( \\lambda_N \\) come moltiplicatori delle componenti di \\( \\vec{a} \\) sulle direzioni degli autovettori.   Ma quel che è più importante, ci consente di calcolare le coordinate del vettore \\( \\vec{a} \\) nel nuovo sistema di riferimento individuato dagli autovettori \\( (v_1, v_2) \\). Vediamo come.   Ricordando che il vettore \\( \\vec{a} \\) è scomponibile nelle due componenti nelle direzioni degli autovettori, supponendo \\( \\vec{v_1} \\) e \\( \\vec{v_2} \\) autovettori normalizzati (cioè con modulo pari a uno), possiamo scrivere questa combinazione lineare:   \\[a = \\alpha v_1 + \\beta v_2\\]  che individua un sistema di equazioni lineari che può essere risolto in \\( (\\alpha, \\beta) \\) così:   \\[\\begin{pmatrix} a_x \\\\\\\\ a_y \\end{pmatrix} = \\alpha\\begin{pmatrix} v_1x \\\\\\\\ v_1y \\end{pmatrix} + \\beta\\begin{pmatrix} v_2x \\\\\\\\ v_2y \\end{pmatrix} \\Rightarrow\\]  \\[\\begin{pmatrix} a_x \\\\\\\\ a_y \\end{pmatrix} = \\begin{pmatrix} \\alpha v_1x + \\beta v_2x \\\\\\\\ \\alpha v_1y + \\beta v_2y \\end{pmatrix} \\Rightarrow\\]  \\[\\begin{pmatrix} a_x \\\\\\\\ a_y \\end{pmatrix} = \\bbox[5px,border:1px solid red]{\\begin{pmatrix} v_1x &amp;&amp; v_2x \\\\\\\\ v_1y &amp;&amp; v_2y \\end{pmatrix}}\\begin{pmatrix} \\alpha \\\\\\\\ \\beta \\end{pmatrix}\\]  Dove la matrice nel riquadro rosso non è altro che la matrice che ha come colonne le componenti normalizzate degli autovettori della matrice di partenza mentre \\( (\\alpha, \\beta)^T \\) è niente altro che la rappresentazione del vettore di partenza \\(\\vec{a} \\) nel nuovo sistema di riferimento dato dagli autovettori.   Se indichiamo la matrice degli autovettori con \\( V \\) possiamo in definitiva scrivere:   \\[\\vec{a} = V\\begin{pmatrix} \\alpha \\\\\\\\ \\beta \\end{pmatrix}\\]  ovvero   \\[\\begin{pmatrix} \\alpha \\\\\\\\ \\beta \\end{pmatrix} = V^{-1}A\\]  Il nuovo sistema di assi così individuato non sarà necessariamente rappresentato da autovettori ortogonali. Tuttavia, questi potranno essere ortogonalizzati facendoli ruotare relativamente uno agli altri in modo da ottenere variazioni di angoli di, giustappunto, 90°.   L’applicazione più concreta del cambio di assi verso un sistema individuato dagli autovettori è proprio nella diagonalizzazione delle matrici che, come detto, ha diversi vantaggi tra cui la semplificazione dei calcoli. Ebbene, possiamo dimostrare che per diagonalizzare una matrice si possono usare gli autovalori per produrre una base di riferimento ortogonale. Se gli autovettori sono ortogonali, il vettore trasformato manterrà, nel nuovo sistema di riferimento, la stessa lunghezza - e questa è certamente la situazione più auspicabile. In caso contrario, il vettore trasformato presenterà una lunghezza diversa.   Ma vediamo come. Ricordando l’equazione fondamentale degli autovettori per cui in uno spazio a \\( N \\) dimensioni abbiamo al più \\( N \\) autovettori e autovalori e la cui espressione del k-esimo è la seguente:   \\[A\\vec{v_k} = \\lambda_k\\vec{v_k} \\text{  con   } k = 1,\\ldots,N\\]  Ovvero   \\[\\begin{matrix} A\\vec{v_1} = \\lambda_1\\vec{v_1} \\\\\\\\ A\\vec{v_2} = \\lambda_2\\vec{v_2} \\\\\\\\ \\vdots \\\\\\\\ A\\vec{v_k} = \\lambda_k\\vec{v_k} \\end{matrix} \\Rightarrow\\]  \\[A(v_1 v_2 \\ldots v_N) = (v_1 v_2 \\ldots v_N)\\Lambda\\]  con i vettori \\( v_k \\) gli autovettori e \\( \\Lambda \\) la matrice degli autovalori che, infatti, vale:   \\[\\Lambda = \\begin{pmatrix} \\lambda_1 &amp; 0 &amp; \\ldots &amp; 0 \\\\\\\\ 0 &amp; \\lambda_2 &amp; \\ldots &amp; 0 \\\\\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\\\\ 0 &amp; 0 &amp; \\ldots &amp; \\lambda_k \\end{pmatrix}\\]  che, come si può vedere, è una matrice che presenta sulla diagonale principale i coefficienti degli autovalori della matrice \\( A \\).   Per finire, andando a indicare con \\( V \\) la matrice degli autovettori utilizzati precedentemente, otterremo l’equazione fondamentale per la diagonalizzazione di una matrice:   \\[\\bbox[5px,border:1px solid red]{ VA = V\\Lambda }\\]  In altri termini, la matrice degli autovalori \\( \\Lambda \\) sarà la rappresentazione diagonale della matrice \\( A \\) in un sistema di riferimento individuato dagli autovettori di \\( A \\), o come si dice più propriamente nell’autospazio di \\( A \\).   Ma a cosa serve tutto ciò?   Una applicazione pratica: la compressione dell’informazione  Sia data una certa matrice quadrata \\( A \\). La matrice degli autovettori esprime la varianza di \\(A \\), ovvero le informazioni che contiene. Il quantitativo di varianza espressa da ogni singolo autovettore è espresso dal valore dell’autovettore corrispondente. Vediamolo con un esempio con la seguente matrice \\( A \\):   \\[A = \\begin{pmatrix} 2 &amp; -1 &amp; 3 \\\\\\\\ 3 &amp; -2 &amp; 2  \\\\\\\\ 15 &amp; -9 &amp; 16 \\end{pmatrix}\\]  (si noti che la matrice A è di ordine 3 con il terzo componente volutamente molto vicino ma non coincidente alla combinazione lineare \\( 3a_1 + 3a_2\\)).   Ora calcoliamo gli autovalori e gli autovettori corrispondenti:   \\[\\begin{matrix} \\lambda_1 = 17.59 \\\\\\\\ \\lambda_2 = -1.62 \\\\\\\\ \\lambda_3 = 0.035 \\end{matrix}\\]  \\[V = \\begin{pmatrix} -0.18 &amp; 0.26 &amp; -0.64 \\\\\\\\ -0.12 &amp; -0.68 &amp; -0.19 \\\\\\\\ -0.97 &amp; -0.68 &amp; 0.74 \\end{pmatrix}\\]  \\[V^-1 = \\begin{pmatrix} -0.81 &amp; 0.47 &amp; -0.93 \\\\\\\\ 1.04 &amp; -0.86 &amp; -0.08 \\\\\\\\ -0.80 &amp; -0.60 &amp; 0.22 \\end{pmatrix}\\]  Notiamo subito che \\( \\lambda_3 \\) è molto più piccolo in modulo degli altri due autovalori. Questo significa che il suo contributo all’informazione contenuta in \\( A \\) è molto ridotto, rispetto agli altri due.   Decidiamo allora di scartarlo e di scartare anche l’autovettore corrispondente.   \\[\\Lambda = \\begin{pmatrix} 17.5 &amp; 0 \\\\\\\\ 0 &amp; -1.6 \\end{pmatrix}\\]  \\[V = \\begin{pmatrix} -0.18 &amp; 0.26 4 \\\\\\\\ -0.12 &amp; -0.68  \\\\\\\\ -0.97 &amp; -0.68  \\end{pmatrix}\\]  \\[V^-1 = \\begin{pmatrix} -0.81 &amp; 0.47 &amp; -0.93 \\\\\\\\ 1.04 &amp; -0.86 &amp; -0.08  \\end{pmatrix}\\]  Ora, dalla formula della diagonalizzazione abbiamo che   \\[A = V\\Lambda V^{-1}\\]  e facendo i calcoli abbiamo questa rappresentazione di \\( A \\) che per distinguerla dall’originaria decoro con un pedice \\( R \\):   \\[A_R = \\begin{pmatrix} 1.98 &amp; -1.01 &amp; 3 \\\\\\\\ 2.97 &amp; -2.01 &amp; 2  \\\\\\\\ 15 &amp; -8.99 &amp; 15.99 \\end{pmatrix}\\]  che non è identica alla matrice \\( A \\), ma è senza dubbio estremamente simile ad essa. Ma ottenuta lavorando con matrici di dimensione 2 invece di 3, ovvero con meno calcoli.   Abbiamo, nel concreto, ricostruito la matrice \\( A \\) utilizzando una sua espressione diagonale valutata su una base di autovettori ridotta rispetto a quella individuabile da \\( A \\) e nel farlo abbiamo perso un quantitativo trascurabile di informazione.   Geometricamente, abbiamo espresso \\( A_R \\) in un sistema di riferimento avente un numero di dimensioni più basso rispetto all’ordine di \\( A \\).   Nella pratica, abbiamo condotto una operazione di compressione dell’informazione.   Autovettori e Social Network Analysis   L’importanza degli autovettori per la scienza dell’informazione, come potete immaginare, già solo per la capacità di ridurre di dimensioni un sistema è estrema. Ma come possiamo applicare questo potente strumento allo studio delle reti sociali?   Per rispondere a questa domanda basta ricordare che noi possiamo sempre esprimere una rete di relazioni attraverso la matrice delle adiacenze. E questa matrice è, tipicamente, non singolare quindi ammette un’inversa e, quindi, su di essa è possibile calcolare gli autovalori e gli autovettori.   Lo vedremo presto su una particolare misura di centralità, chiamata Eigenvector Centrality, sulla quale si è molto parlato negli ultimi anni e ancora di più se ne parlerà in futuro.   E’ la modalità, infatti, su cui Google ha costruito il suo famigerato algoritmo PageRank, per stimare l’autorevolezza e ordinare i link nei risultati del motore di ricerca.   Esatto, Google. E parte tutto da qui.  ","categories": ["Matematica"],
        "tags": [],
        "url": "https://gabrielebaldassarre.com/introduzione-autovettori-autovalori/",
        "teaser": "https://gabrielebaldassarre.com/assets/images/eigenvectors-teaser.jpg"
      },{
        "title": "Una rete sociale fatta di comunità",
        "excerpt":"Nel corso di tutto il XX Secolo, i sociologi e gli studiosi di topologia e di reti ci hanno deliziato con modelli non solo sempre più credibili e realistici per descrivere una rete sociale, ma anche con sorprendenti similitudini e simmetrie con tante reti spontaneamente presenti in natura, in una sorta di elegante rappresentazione unificata della realtà.   Il caso più noto è certamente quello della Teoria del mondo piccolo, quella dei sei gradi di separazione per intenderci, e della Rete Small-World da essa descritta. Accompagnato da un esperimento non proprio rigoroso, ma goloso dal punto di vista mediatico, qualche pellicola cinematografica e, in tempi più recenti, un po’ di intrigo complottistico in salsa social, il modello è anche uno dei primi che si studia in Social Network Analysis. Ebbene, sotto opportune condizioni lo Small-World si ritrova in tante reti, naturali e non, come quelle descritte dai neuroni del cervello, le reti di diffusione dell’energia elettrica, i commutatori telefoni, ecc., e questo ha contribuito non poco alla sua attrattiva per i non addetti ai lavori.   Sfortunatamente per gli hippie e per i fisici, però, il XXI Secolo si è aperto con una serie di studi che ci hanno mostrato una realtà un po’ più complessa, che rompe, almeno per ora, la simmetria con neuroni, telefoni e relé e, forse, fa perdere un po’ di fascino al tutto. Le reti sociali umane sono sì delle reti Small-World, ma hanno anche alcune caratteristiche uniche.   Ma prima di parlare di questo modello più evoluto, vediamo innanzitutto brevemente come si è chiuso il XX Secolo in casa dei sociologi.       Stanley Milgram, lo psicologo statunitense che, nell’ambito dell’arcinoto esperimento, nel 1967 spedì lettere in giro per tutti gli Stati Uniti e dimostrò che viviamo in un mondo piccolo. Non tutti sanno, però, che prima di lui l’esistenza dello Small-World effect era stata speculata dallo scrittore ungherese Frigyers Karinthy mentre Ithiel de Sola Pool e Manfred Kochen colmarono, nel 1978 e con un rigoroso  modello matematico, le lacune dell’illustre, e discusso, predecessore (foto: Psychology Unlocked).   Cosa si sapeva già: le tre caratteristiche di una rete sociale   Per lungo tempo, tre sono state, in linea di principio, le caratteristiche che sembravano mettere d’accordo tutte (o quasi) le reti sociali sui quali si avevano dati attendibili. Queste caratteristiche riscontrate nelle reti hanno consentito di costruire modelli via via più complessi e realistici e che descrivono in maniera sempre più accurata la complessità delle relazioni umane.   Viviamo in un mondo piccolo   Questa caratteristica, dimostrata empiricamente con l’esperimento di Milgram, suggerisce che la distanza media tra due nodi qualunque della rete è relativamente piccola. Tradotto, questo significa che, scelti due nodi della rete, essi sono connessi attraverso un numero di nodi intermedi molto piccolo se confrontato con la dimensione della rete stessa.   Più precisamente, il diametro della rete è, sì, proporzionale al numero di nodi, ma cresce su scala solo logaritmica rispetto al numero di nodi \\( n \\). Questo comporta che al crescere del numero di nodi di una rete, il diametro cresce, ma più lentamente.   Qui è racchiusa l’essenza dei  sei gradi di separazione. E’ una caratteristica che non è di esclusivo appannaggio delle reti sociali, ma è stata riscontrata anche in reti di informazioni, reti tecnologiche e persino reti biologiche. Oltre ai succitati sei gradi dell’esperimento di Milgram (scesi, sembrerebbe, a 4.7 dall’avvento di Facebook), diametri contenuti il propozione alle dimensioni della rete si hanno nel World Wide Web (stimato in circa 19), nelle connesisoni neuronali e in molte altre circostanze.   Gli amici dei miei amici sono miei amici   Così come il DNA è costruito da una sequenza di quattro basi elementari (adenina, guanina,…) così anche le reti sociali hanno le loro “basi”. Queste basi sono le differenti combinazioni di collegamenti possibili tra tre nodi della rete, scelti casualmente.   Il motivo per cui l’elemento più atomico di organizzazione delle comunità sociali sia il triangolo è ancora oggetto di studi e non vi ci addentreremo in questa sete. Fatto sta, che, come una catena di DNA è descritta da una lunga sequenza di basi, una rete sociale può essere descritta da una lunga sequenza di triangoli. Questi triangoli prendono il nome di triadi o, più spesso, di clique (in italiano orribilmente traducibile con ‘cricca’). E queste clique non sono, tipicamente, oggetti statici; le relazioni evolvono nel tempo e la struttura della rete con esso. Con essa, quindi, cambiano le clique.       Una serie di clique, o triadi. In effetti, diverse possono essere le configurazioni con cui si presenta una triade aperta o chiusa. Tra questi esempi, l’unica caratterizzata da una certa instabilità è quella di sinistra che non a caso prende il nome di triade proibita (forbidden triad): la probabilità che evolva, presto o tardi, in una delle due configurazioni più a destra è molto alta.   Il motivo per cui avviene questa “risoluzione” della clique ha cause fisiche: minimizzazione dell’energia. Troppo dispendiosa di energie, infatti, è la situazione del nodo A, costretto a mantenere due canali segregati con C e B in una situazione di perenne stress sociale. Molto più facile risolverla facendo sì che i due nodi non connessi tra di loro entrino in contatto oppure interrompendo la relazione con uno dei due vicini (C, in questo caso).   La “forza” che eventualmente spinge verso la prima delle due evoluzioni appena descritte è la  transitività ed è una caratteristica osservabile in molte reti sociali e anche in alcune reti di informazioni (come gli scambi di email in un’azienda). Detto anche clustering, perché spinge la rete a organizzarsi in grappoli strettamente connessi, è modellizabile con degli opportuni coefficienti che, in linea di principio, hanno lo scopo di misurare la densità e la tipologia di clique in una rete.   Follow the leader   Pensare alle reti come oggetti statici è un errore: le reti sociali si aggiornano di continuo introducendo nuovi nodi e nuovi collegamenti vengono a crearsi, mentre altri vengono recisi; solo che, talvolta, l’evoluzione è lenta e le variazioni impercettibili al punto che la rete stessa ci sembra un oggetto statico e immutabile.   Ebbene, quando una rete sociale è in espansione, si può osservare che i nuovi nodi entranti tenderanno a estrudere collegamenti verso i nodi della rete che ne presentano già molti altri, come se la popolarità di un nodo attirasse a sé i nuovi arrivati. Questo comportamento, chiamato attaccamento preferenziale crea delle strutture di rete in cui pochi nodi molto influenti, gli hub, o se vogliamo i leader, detengono un numero di collegamenti attivi molto superiore alla media degli altri nodi della rete. Le reti sociali presentano questa caratteristica, ma non tutte e comunque non tutte le reti (per es. il fenomeno è molto più raro nelle reti di informazione, come Internet).   Capire se ci troviamo di fronte a una rete di questo tipo, che per inciso prende il nome di scale-free,  non è difficile: basta studiare la distribuzione del grado di tutti i nodi della rete. In una rete non scale-free non abbiamo motivo di sospettare la presenza di hub privilegiati perché la probabilità di un nodo di avere \\( k \\) connessioni è identica per tutti i nodi della rete e vale \\( p(k) \\). E, in effetti, la degree centrality di distribuisce secondo una distribuzione simmetrica (la binomiale, nella fattispecie) attorno alla degree centrality media \\( k_{avg} \\).   Una rete scale-free munita, come detto, di hubs presenterà, invece, una distribuzione con una coda molto lunga sulla destra, dove ci sono nodi con una degree centrality di molto superiore alla media. Più precisamente, la degree centrality segue la legge di potenza, o power law.       La distribuzione del numero dei collegamenti dei nodi per una rete non scale-free (a sinistra) con una scale-free (a destra). Sull’asse delle ascisse il numero di connessioni \\( k \\) di un nodo, sulle ordinate la percentuale di nodi tra tutti quelli della rete ad avere esattamente \\( k \\) connessioni. In una rete non scale-free si ha il tipico andamento a campana di una binomiale (o di una Poisson o anche di una normale, a seconda delle approssimazioni applicate al modello) con la maggior parte dei nodi avente un numero di nodi vicino alla media e scarsa probabilità di avere degli hub o dei nodi fortemente disconessi. Una rete scale-free, invece, ha l’andamento tipico di una power law, con la maggior parte dei nodi ad avere poche connessioni e pochi nodi ad avere un numero di connessioni \\( k \\) molto maggiori della media \\( k_{avg} \\).   Solo una puntualizzazione sul nome: queste reti si chiamano scale-free perché la pendenza della retta caratteristica del modello di regressione costruito sulla distribuzione della centralità è invariante alla scala,  cioè non varia al variare del numero dei nodi. Solo, tuttavia, questa grandezza presenta questa caratteristica, mentre tipicamente le altre grandezze caratteristiche (strutturali, come la centralitò, o attributi legati ai nodi) sono genericamente non invarianti.   L’importanza delle community locali   Innanzitutto una precisazione: non è che solo nel XXI secolo i ricercatori si siano accorti che gli esseri umani tendono a individuare delle community più o meno con le altre regioni della rete. Questa è una scoperta ben più antica, con cui sociologi, antropologi e, in tempi ancor più remoti, persino filosofi si sono confrontati. Quello che, però, mancava era un’adeguata rappresentazione mediante un modello che potesse essere utilizzato in Social Network Analysis.   Un primo modello che descrive la creazione di community in una rete è stato un modello puramente gerarchico, che pensa alle community un po’ come alle organizzazioni militari, cioè in raggruppamenti aggregati che crescono progressivamente di dimensione (es. plotoni che formano compagnie che a loro volta formano battaglioni, reggimenti, ecc.). Presto, però, si è scoperto che questo modello era troppo schematico per rappresentare correttamente la realtà delle relazioni tra gli individui.   Il buon senso ci suggerisce che le community locali si creano attorno agli individui che hanno qualcosa in comune, per es. l’età, la razza, la religione, la passione per i film di fantascienza. L’affinità tra questi individui è alta e, quindi, è più alta la probabilità che tra di loro si instauri un legame.   In gergo, questo comportamento è chiamato mixing e una rete che favorisce la coesione tra nodi affini è una rete soggetta ad assortative mixing (o anche omofilia). Al contrario, una rete che favorisce le relazioni tra individui non affini viene detta una rete soggetta a disassortative mixing.       Una stessa rete può essere sia assortativa che disassortativa, in base all’attributo scelto per esprimere la relazione. Una rete di adolescenti, ad esempio, è probabile che sia assortativa attorno a un attributo come l’età, ma sarà quasi certamente disassortativa su un attributo come il sesso se i legami esprimono relazioni sentimentali (la probabilità di un legame tra due nodi è più alta se essi non sono dello stesso sesso).   Esiste, però, una particolare relazione di (dis)assortatività e cioè quella legata al numero di connessioni dei nodi (la degree centrality o grado) che possiamo riassumere in una semplice domanda: i nodi con un elevato numero connessioni tenderanno a collegarsi ad altri nodi con molte connessioni o preferiranno nodi con un basso numero di connessioni?       Reti assortative e disassortative in riferimento al numero di connessioni (grado). In una rete assortativa (a sinistra) abbiamo una elevata densità di nodi con tante connessioni al centro, in un grande componente molto connesso, e una periferia di nodi con poche connessioni. In una rete disassortativa (a destra) invece avremo una distribuzione più uniforme tra centro e periferia e nodi con basso numero di connessioni adiacenti a nodi più popolari.   Ebbene, molte reti sociali e per la verità tutte quelle che sembrano organizzarsi in community, a prescindere dalle loro dimensioni, sono assortative sul grado. Tipici esempi sono la rete individuata dalle collaborazioni scientifiche (tenendo conto che nella maggior parte dei casi i paper scientifici sono scritti a più mani da diversi studiosi e ricercatori) e la rete dei membri dei consigli di amministrazione delle aziende.   Al contrario, reti tipicamente disassortative sul numero di gradi sono quelle biologiche, come le reti individuate tra le proteine di una cellula.   La risposta alla domanda, comunque, è affermativa: i nodi con alta degree tenderanno a connettersi ai vicini più prossimi con alta degree, di fatto contribuendo al loro prestigio (e facilitandone le comunicazioni). Sembra poco, ma è la definizione di comunità per come la percepiscono gli esseri umani: comportamento assortativo verso i membri della propria community, e quindi tante connessioni e cluster molto stretti di individui con un fitto reticolo di connessioni che li tengono insieme, e comportamento disassortativo verso i membri delle altre community, raggiunti da sporadici connessioni che fungono da “ponte” tra le diverse community costituenti la rete.   Non solo: se la rete è abbastanza fitta (e si può determinare anche numericamente quanto), questo fenomeno causa l’emergere di una community in genere di gran lunga più grande delle altre e di cui fanno parte la maggior parte dei nodi della rete: il cosiddetto giant component. Lo studieremo nel dettaglio in futuro.   Oltre a fornirci il modello matematico con cui analizzare una rete fatta di comunità questa scoperta è fenomenale: ci fa capire come siano gli sporadici legami tra community diverse a essere essenziali per veicolare un messaggio, diffondere una notizia, capire in quanto tempo si diffonderà un virus ecc. nella totalità della rete. I (molti) legami presenti tra gli individui di una stessa community contribuiranno certamente alla velocità con cui il messaggio si distribuisce all’interno della community stessa, ma sono inutili affinché il segnale travalichi i confini della community locale per “infettare” la rete nella sua interezza.   E’ quello che si intende forza dei legami deboli, e merita che se ne parli in un articolo dedicato.  ","categories": ["Social Network Analysis"],
        "tags": [],
        "url": "https://gabrielebaldassarre.com/community-network-model/",
        "teaser": "https://gabrielebaldassarre.com/assets/images/default-post-teaser.png"
      },{
        "title": "Approfondimento matematico: la power law",
        "excerpt":"```{r powerlaw.setup, include = FALSE, cache = FALSE} if (!require(\"pacman\")) install.packages(\"pacman\"); invisible(library(pacman)) tryCatch({   p_load(\"tidyverse\", \"poweRlaw\", \"rprojroot\") }, warning=function(w){   stop(conditionMessage(w)) })  old.par  1 \\\\), cosa che avviene _sempre_, per far sì che un intervallo abbia meno campioni dell'intervallo immediatamente alla sua sinistra.  Fortunatamente esiste un modo ancora migliore per rappresentare (e studiare) una power law e consiste nel rappresentarla mediante la __distribuzione di probabilità cumulativa__ (cumulative distribution function, o __CDF__).  Se indichiamo con \\\\( P(x) \\\\) la probabilità che \\\\( x \\\\) abbia un valore non più semplicemente uguale ma __maggiore o uguale__ a \\\\( x \\\\)  $$ P(x) = \\int_x^\\infty p(x^\\prime)dx^\\prime $$  Poiché la \\\\( p(x) \\\\) è una power law di tipo  $$ p(x) = Cx^{-\\alpha} $$  possiamo scrivere  $$ P(x) = C\\int_x^\\infty x^{\\prime-\\alpha}dx^\\prime = \\bbox[5px,border:1px solid red]{ \\frac{C}{\\alpha - 1}x^{-(\\alpha - 1 )}} \\tag{CDF} $$  La CDF \\\\( P(x) \\\\) di una power law (nel box rosso) è a sua volta, come si può vedere, una power law ma con esponente \\\\( \\alpha - 1 \\\\); questo significa che una volta rappresentata su scala log-log presenterà ancora un andamento rettilineo, ma con una pendenza diversa. Soprattutto,  essa è stata ottenuta _senza_ un binning, quindi senza perdita di informazioni e senza aver dovuto formulare alcuna ipotesi sull'ampiezza degli intervalli (ovvero, fare una scelta empirica). Ancora una volta, usiamo il dataset di Moby Dick per visualizzare la CDF:  ```{r mobydick.cdf, fig.asp = 1, fig.alt=\"\"} moby.pl <- conpl$new(moby) moby.pl$setXmin(estimate_xmin(moby.pl)) moby.pl$setPars(estimate_pars(moby.pl))  plot(moby.pl, pch = 16, cex = .2, col = \"darkblue\", bg=2, panel.first=grid(col=\"grey80\"),      xlab=\"Frequenza\", ylab=\"CDF\", main = \"Moby Dick - CDF\") lines(moby.pl, col=2, lwd = 1.4) ```  La CDF del campione è, come si può vedere, molto \"pulita\" e segue con notevole precisione l'andamento di una power law avente $$ \\alpha = `r format(moby.pl$getPars(), digits = 2, nsmall = 2)` $$ (retta in rosso).  ## Determinare i parametri della power law  Per quanto molto comune in natura, sono poche le grandezze che presentano un andamento che segue la legge di potenza nell'interezza dei valori della loro CDF; più spesso, si riscontrano distribuzioni che assimilano la legge di potenza sulla parte _destra_ del loro dominio (come nell'esempio sopra), mentre la parte sinistra segue un andamento diverso.  Per questo motivo, è prassi abbastanza comune individuare il valore \\\\( x_{min} \\\\) al di sopra del quale la distribuzione, si verifica, segue in modo soddisfacente la legge di potenza, mentre per i valori al di sotto è opportuno individuare un modello che esprima con minore incertezza l'andamento della CDF, perché la _power law_ non modella adeguatamente la distribuzione; spesso, per questi valori bassi, migliori risultati si hanno con modelli di tipo esponenziale, log-normali o di Poisson. Nell'esempio di Moby Dick, per dire, ha senso applicare il modello _power law_ di cui sopra solo per $$ x_{min} \\ge `r moby.pl$getXmin() ` $$  La stima di \\\\( x_{min} \\\\) può essere fatta in modo visivo, dal grafico della CDF, oppure analiticamente, in modo da avere una stima statisticamente robusta e che, soprattutto, non richieda l'intervento diretto dell'osservatore per l'interpretazione.  L'idea alla base è piuttosto semplice: scegliamo un valore \\\\( \\hat{x} \\\\) tale che renda le distribuzioni di probabilità e la migliore _power law_ applicabile (con un dato \\\\( \\alpha \\\\)) il più simile possibile per valori sopra \\\\( \\hat{x} \\\\). Se il valore di \\\\( \\hat x_{min} \\\\) è superiore del valore vero di \\\\( x_{min} \\\\), questo implica scartare un maggior numero di osservazioni (sotto \\\\( x_{min} \\\\)) e, quindi, ottenere, una distribuzione di probabilità più scadente, per via delle fluttuazioni statistiche. D'altra parte, se il valore di \\\\( \\hat{x} \\\\) è inferiore al valore vero di \\\\( x_{min} \\\\), le distribuzioni di probabilità divergeranno per la sostanziale differenza tra i dati e il modello stesso. Il valore migliore di \\\\( x_{min} \\\\) giace all'interno di questo intervallo.  La migliore misura per quantificare la distanza tra due distribuzioni di probabilità, per dati che palesemente non seguono la distribuzione nornale, è la statistica KS (o Kolmogorof-Smirnov), ovvero la massima distanza tra le CDF dei dati e il modello:  $$ D = \\max_{x \\ge x_{min}} \\left\\lvert S(x) - P(x) \\right\\rvert $$  con \\\\( S(x) \\\\) che rappresenta la CDF delle osservazioni per valori che siano almeno \\\\( x_{min} \\\\) e \\\\( P(x) \\\\) la CDF del modello _power law_ che rappresenta la miglior stima possibile. La stima \\\\( \\hat{x} \\\\) di \\\\( x_{min} \\\\) è quella che minimizza \\\\( D \\\\).  Una volta individuato un soddisfacente \\\\( x_{min} \\\\), è possibile stimare un adeguato \\\\( \\alpha \\\\). Per farlo, l'approccio migliore è utilizzare il [metodo della massima verosmiglianza](https://it.wikipedia.org/wiki/Metodo_della_massima_verosimiglianza) (MLE), posto che vi sia un adeguato numero di osservazioni con \\\\( x \\ge x_{min} \\\\). LA MLE per il caso continuo è la seguente (quella per il caso discreto è molto più complessa e non verrà trattata in questa sede):  $$ \\hat{\\alpha} = 1 + n\\left[\\sum_{i=1}^n \\ln\\frac{x_i}{x_{min}}\\right] \\tag{MLE} $$  Dove \\\\( \\hat{\\alpha} \\\\) è il valore stimato per \\\\( \\alpha \\\\), normalmente non noto, individuato da una popolazione di \\\\( n \\\\) osservazioni \\\\( x_i \\\\) con \\\\( i = 1, 2, \\dots, n \\\\), tutti tale che \\\\( x_i \\ge x_{min} \\\\).  Naturalmente, la robustezza di tali stimatori va anche essa valutata con un opportuno test per l'ipotesi, ma per essa vi chiedo di attendere il secondo articolo sull'argomento che ho in lavorazione, che riporterà degli esempi pratici in R e che toccherà anche questi temi ulteriori.  ## Esempi noti in letteratura  Dai ricercatori, sono stati spesso studiati e citati dei campioni che esprimono un andamento della CDF come legge di potenza. Vediamo i più famosi:  * __Frequenza delle parole nei testi__ - lo abbiamo visto con Moby Dick, ma il linguista [George Kingsley Zipf](https://en.wikipedia.org/wiki/George_Kingsley_Zipf) ha potuto verificare come questo accada in tutta la letteratura occidentale. La trattazione è riportata in [un suo elegante lavoro](https://www.amazon.it/Human-Behavior-Principle-Least-Effort/dp/161427312X) del 1949.  * __Citazioni nelle pubblicazioni scientifiche__ - dimostrata da Derek J. de Solla Price in un [articolo su Science](http://garfield.library.upenn.edu/papers/pricenetworks1965.pdf) nel lontano 1965.  ## Un esempio tutto nostro: i comuni italiani  Per completare la trattazione, volevo brevemente studiare un campione che molto spesso, in letteratura, è stato assimilato ad una _power law_: la popolazione degli insediamenti umani in una data nazione.  ```{r italian.towns} italian.towns <- read.csv2(find_root_file(\"R\", \"data\", \"ISTAT\", \"comuni_italiani.csv\", criterion = is_git_root))  bins <- 100  population.bins <- hist(italian.towns$PopResidente,                         breaks = seq(from = min(italian.towns$PopResidente),                                      to = max(italian.towns$PopResidente), length.out = bins),                         plot=FALSE)  population.log.bins <- hist(italian.towns$PopResidente,            breaks = exp(seq(log(min(italian.towns$PopResidente)), log(max(italian.towns$PopResidente)), len = bins)),            plot=FALSE)  # Log Binning # (better than linear binning due to the nature of data)  italian.pl <- conpl$new(italian.towns$PopResidente) italian.pl$setXmin(estimate_xmin(italian.pl)) italian.pl$setPars(estimate_pars(italian.pl))  italian.ln <- conlnorm$new(italian.towns$PopResidente) italian.ln$setXmin(estimate_xmin(italian.ln)) italian.ln$setPars(estimate_pars(italian.ln)) ```  Così, per essere originale, ho ben pensato di studiare il dataset dei communi italiani, messo a disposizione dall'ISTAT a valle dell'ultimo censimento nazionale. Si tratta di un dataset di `r nrow(italian.towns) ` comuni italiani con una popolazione compresa tra `r min(italian.towns$PopResidente)` e `r max(italian.towns$PopResidente)` abitanti.  Il valore del più piccolo comune d'Italia,  (`r min(italian.towns$PopResidente)`, si tratta del comune di `r italian.towns[which(italian.towns$PopResidente == min(italian.towns$PopResidente)),]$Comune `, in provincia di `r italian.towns[which(italian.towns$PopResidente == min(italian.towns$PopResidente)),]$Provincia `) mi ha fatto subito sospettare che la parte sinistra della distribuzione avesse un comportamento singolare (difficile pensare che ci siano più comuni di `r min(italian.towns$PopResidente)` abitanti rispetto agli altri).  Prima, però, di stimare un \\\\( x_{min} \\\\) per la CDF, mi sono chiesto se la distribuzione, una volta applicato il binning logaritmico, non potesse assumere una forma canonica. Così, dopo aver segmentato la popolazione in `r bins ` intervalli ho ottenuto questo plot della densità e della percentuale di osservazioni.  ```{r italian.towns.plots, fig.asp = .5} old.par <- par()  par(mar=c(4, 4, 2, 1),     mgp=c(3, 0.4, 0),     tck=-.01,     oma=c(0,1,2,0),     cex.axis=0.9,     las=1)  par(mfrow=c(1,2))  # Log-binning counts in log-log scale shows a log-norm behaviour plot(population.log.bins$mids,      population.log.bins$density,      cex = .4,      type = \"p\",      pch = 16,      col = \"darkblue\",      log = \"xy\",      ylab = \"Comuni [Densità]\",      xlab = \"Popolazione\",      panel.first=grid(col=\"grey80\"),      main = \"Densità\")  plot(population.log.bins$mids,      population.log.bins$counts/sum(population.log.bins$counts),      cex = .4,      type = \"p\",      pch = 16,      col = \"darkblue\",      log = \"xy\",      ylab = \"Comuni [%]\",      xlab = \"Popolazione\",      panel.first=grid(col=\"grey80\"),      main = \"Osservazioni\")  title(\"Comuni Italiani - Logarithmic Binning\", outer=TRUE) ```  Ebbene, questo grafico mi ha subito dato la sensazione di un andamento che segue una [distribuzione log-normale](https://it.wikipedia.org/wiki/Distribuzione_lognormale), con una leggera distonia sulla \"coda\" destra che può essere imputabile a un andamento secondo la legge di potenza.  Il prossimo passo è stato, perciò, quello di individuare, attraverso il metodo di massima verosimiglianza spiegato sopra, due modelli, uno di tipo _power law_ e uno di tipo log-normale. L'ho fatto, naturalmente, sulla CDF e ho ottenuto il seguente:  ```{r italian.towns.cdf}  par(mfrow=c(1,1))  plot(italian.pl, pch = 16, cex = .2, col = \"darkblue\", bg=2, panel.first=grid(col=\"grey80\"),      xlab=\"Popolazione\", ylab=\"CDF\", main = \"Comuni Italiani - Modelli su CDF\") lines(italian.pl, col=2, lwd = 1.4) lines(italian.ln, col=3, lwd = 1.4) ```  Ebbene, come previsto il modello log-normale (in verde) riesce a descrivere il campione per gran parte del suo codominio (ha \\\\( x_{min_1} = `r italian.ln$xmin`\\\\), fino a \\\\( x_{min_2} = `r italian.pl$xmin`\\\\), al di sopra del quale è la legge di potenza (in rosso) caratterizzata dal parametro \\\\( \\alpha = `r format(italian.pl$getPars(), digits = 2, nsmall = 2)` \\\\) a descrivere meglio la curva di distribuzione della CDF.  Poiché, per ciò che avevamo ipotizzato sui dati, lo studio della funzione non è interessante per valori inferiori di \\\\( x_{min_1} \\\\), il _fitting_ si può arrestare qui. Ciò che bisognerebbe fare per terminare il lavoro è, come dicevamo, un opportuno test per verificare la robustezza degli stimatori, ma oggettivamente, nel caso specifico l'ispezione visiva dei grafici fornisce già, con discreto margine di sicurezza, le garanzie necessarie.  ## Per approfondire  * M. E. J. Newman, [Power laws, Pareto distributions and Zipf’s law](https://arxiv.org/pdf/cond-mat/0412004.pdf), 2006; * Aaron Clauset, Cosma Rohilla Shalizi, M. E. J. Newman, [Power Laws Distributions in Empirical Data](https://arxiv.org/pdf/0706.1062.pdf), 2009 ","categories": ["Matematica"],
        "tags": [],
        "url": "https://gabrielebaldassarre.com/legge-potenza-powerlaw/",
        "teaser": "https://gabrielebaldassarre.com/assets/images/powerlaw-teaser.jpg"
      },{
        "title": "Approfondimento matematico: la power law",
        "excerpt":"Le legge di potenza altri non è che una funzione matematica con un andamento esponenziale caratterizzato da un parametro che può essere sia negativo che positivo e che nella sua forma più generale si esprime come   \\[f(x) = ax^k\\]  e di per sé non ha niente di speciale.   Diventa, però, interessante quando descrive una distribuzione di probabilità, ovvero la probabilità del verificarsi degli eventi misurati sull’ascissa. In questo frangente, si può osservare che tantissimi fenomeni fisici, dalla dimensione delle città a quella dei crateri da impatto, dalla magnitudine dei terremoti all’attenuazione acustiva, seguono qusto andamento.   Ma prima di addentrarci nello studio della legge di potenza, facciamo alcuni esempi chiarificatori di come si presentano, spesso, le grandezze in natura.   Distribuzioni normali e…meno normali   Il modo più “naturale” in cui ci aspettiamo di misurare una grandezza è una distribuzione centrale, dove la maggior parte delle osservazioni si concentrano attorno a un valore tipico, il valore medio, e decadono molto velocemente in modo simmetrico ai due estremi. Molte distribuzioni, sia presenti in natura che costruite dall’uomo, hanno queste caratteristiche, che possono essere descritte, con un livello più o meno accettabile di approssimazione, con tutta una famiglia di modelli statistici, come la distribuzione gaussiana, la distribuzione binomiale e la quella di Poisson che, dati una serie di parametri, è in grado di spiegare e descrivere la popolazione.   Non è detto, però, che le osservazioni si distribuiscano in modo simmetrico attorno ad un valore tipico. Alcune grandezze, infatti, si esprimono in popolazioni in cui si ha la maggioranza delle osservazioni su valori bassi delle ascisse, ma presentano anche diverse osservazioni molto a destra, in una lunga coda , con osservazioni che possono raggiungere valori della ascissa molto grandi, anche di diversi ordini di granzezza più grandi della media. Quello più sotto ne è un tipico esempio.      Il grafico in scala log-log, mostra chiaramente un andamento assimilabile a quello di una retta per buona parte del suo dominio. Non lo è, apparentemente, nella parte più a destra, dove, però, vige più che altro un elevato errore di campionamento (come dicevamo, sono pochissime le parole ad avere un numero di occorrenze così elevato).   Passiamo ora dalle frequenze alle probabilità e quindi al differenziale. Se definiamo come \\( p(x)dx \\) la frazione di parole con un numero di occorrenze compreso tra \\( x \\) e \\( x + dx \\) e ci troviamo in un andamento più o meno rettilineo come quello appena evidenziato, allora la funzione, su scala logaritmica, può essere descritta come   \\[\\ln p(x) = -\\alpha \\ln x + c\\]  con \\( \\alpha \\) e \\( c \\) costanti. Elevando su \\( e \\) otteniamo la cosiddetta legge di potenza (o power law).   \\(p(x) = Cx^{-\\alpha} \\tag{*}\\) con \\( C = e^c \\).   Una volta definito \\( \\alpha \\), che è il parametro caratterizzante e che in genere (e soprattutto in ambito SNA) è compreso tra 2 e 3, e comunque non è mai minore di 1,  abbiamo tutto ciò che ci serve per descrivere la distribuzione. Il coefficiente \\( C \\), infatti, non è per nulla interessante ai fini pratici, dato che è semplicemente il termine che garantisce che la somma dell’area sottesa dalla curva sia 1, come obbligatorio che sia trovandoci di fronte a una funzione di probabilità.   In natura sono migliaia le grandezze che seguono la legge di potenza nel loro andamento probabilistico e spaziano dall’astronomia, alla linguistica (come abbiamo visto) fino, naturalmente, alle scienze sociali. Tuttavia, molto raramente una grandezza segue una power law sull’interezza delle misure che assume. Più spesso, essa segue questo andamento a tratti, mentre in altre regioni il suo andamento segue leggi diverse.   D’altra parte, per ciò che concerne in nostri scopi, poter affermare che una rete sociale segua, per alcuni suoi attributi (come, ad esempio, il grado) la legge di potenza, ci consente di poter desumere moltissimo sulla sua natura. Non è quindi una affermazione da fare alla leggera!   Per questo motivo, ora che sappiamo quali sono le sue caratteristiche, resta da capire come studiarla.   Individuare una distribuzione power law  Innanzitutto una premessa, che facciamo riprendendo l’esempio di prima: dire che la r-esima parola più ricorrente in Moby Dick viene usata n volte è esattamente la stessa cosa di dire che esistono r parole che occorrono con una frequenza pari almenoa n (per capirci, r sta per rank).   Intanto, questo ci consente di pensare alla legge di potenza come a una funzione di distribuzione cumulativa di probabilità, e questo è utile a prescindere.   Ma, tornando all’interpretazione; il modo più semplice per individuare una power law è, in prima istanza, con un istogramma. Lo abbiamo involontariamente già visto con l’esempio precedente, in cui abbiamo rappresentato la popolazione in questa forma,  usando punti invece che barre per non affollare il grafico e riportando sulle ascisse gli intervalli \\( k, k+n \\) di occorrenze nel testo e sulle ordinate il conteggio delle parole contenute in tali intervalli. In particolare, l’andamento (quasi) lineare del grafico su assi logaritmici ci ha fatto pensare a una power law.   L’istogramma è stato costruito affinché l’ampiezza delle “barre” (o, più propriamente, bin o meglio ancora intervalli) fosse costante; il grafico che ne è risultato è decisamente ben definito nella parte sinistra, dove si concentrano la maggior parte delle osservazioni, ma molto confuso sulla coda di destra, dove ogni intervallo dell’istogramma ha pochi elementi e perciò le piccole fluttuazioni nel numero di componenti nel gruppo causa un grande scostamento sul grafico su scala logaritmica. Il problema è serio: andando a costruire su quel campione un modello di regressione per stimare il modulo di \\( \\alpha \\), il rumore statistico sulla coda interverrà negativamente su di esso, introducendo una forte sottostima nel coefficiente.   Un modo più accurato consiste allora nel variare la dimensione degli intervalli dell’isogramma con uno schema costante e normalizzare i risultati, in modo da ottenere un conteggio per unità di grandezza di x. Questa operazione si chiama non-linear binning.   La logica più comune di binning è quella su base logaritmica, creando una sequenza di intervalli di dimensione esponenzialmente crescente ad es. \\( 2^0=1, 2^1=2, 2^2=4, 2^3=8,…\\) In questo modo, gli intervalli a destra otterranno un maggior numero di campioni, abbattendo il rumore statistico. Applichiamo questa trasformazione ai dati di Moby Dick:      Il grafico di destra, su scala logaritmica, è ancora una volta quello più interessante. Grazie al logarithmic binning, infatti, abbiamo linearizzato efficacemente anche la parte destra della distribuzione e ora è possibile applicare una regressione per stimare \\( \\alpha \\). Tuttavia, noterete come i punti caratterizzanti ora siano molti di meno.   In effetti, per eliminare il rumore si è reso necessario creare degli intervalli molto ampi e questo ha comportato una notevole perdita di informazioni. Per spiegare meglio il concetto: una volta aggregate le misurazioni all’interno di un bin, le abbiamo perse come entità distinte. E tanto più ampi sono gli intervalli, tante più sono le osservazioni che abbiamo aggregato insieme, e sulle quali non è più possibile affermare nulla singolarmente.   In particolare, è sufficiente che \\( \\alpha &gt; 1 \\), cosa che avviene sempre, per far sì che un intervallo abbia meno campioni dell’intervallo immediatamente alla sua sinistra.   Fortunatamente esiste un modo ancora migliore per rappresentare (e studiare) una power law e consiste nel rappresentarla mediante la distribuzione di probabilità cumulativa (cumulative distribution function, o CDF).   Se indichiamo con \\( P(x) \\) la probabilità che \\( x \\) abbia un valore non più semplicemente uguale ma maggiore o uguale a \\( x \\)   \\[P(x) = \\int_x^\\infty p(x^\\prime)dx^\\prime\\]  Poiché la \\( p(x) \\) è una power law di tipo   \\[p(x) = Cx^{-\\alpha}\\]  possiamo scrivere   \\[P(x) = C\\int_x^\\infty x^{\\prime-\\alpha}dx^\\prime = \\bbox[5px,border:1px solid red]{ \\frac{C}{\\alpha - 1}x^{-(\\alpha - 1 )}} \\tag{CDF}\\]  La CDF \\( P(x) \\) di una power law (nel box rosso) è a sua volta, come si può vedere, una power law ma con esponente \\( \\alpha - 1 \\); questo significa che una volta rappresentata su scala log-log presenterà ancora un andamento rettilineo, ma con una pendenza diversa. Soprattutto,  essa è stata ottenuta senza un binning, quindi senza perdita di informazioni e senza aver dovuto formulare alcuna ipotesi sull’ampiezza degli intervalli (ovvero, fare una scelta empirica). Ancora una volta, usiamo il dataset di Moby Dick per visualizzare la CDF:      La CDF del campione è, come si può vedere, molto “pulita” e segue con notevole precisione l’andamento di una power law avente \\(\\alpha = 1.93\\) (retta in rosso).   Determinare i parametri della power law   Per quanto molto comune in natura, sono poche le grandezze che presentano un andamento che segue la legge di potenza nell’interezza dei valori della loro CDF; più spesso, si riscontrano distribuzioni che assimilano la legge di potenza sulla parte destra del loro dominio (come nell’esempio sopra), mentre la parte sinistra segue un andamento diverso.   Per questo motivo, è prassi abbastanza comune individuare il valore \\( x_{min} \\) al di sopra del quale la distribuzione, si verifica, segue in modo soddisfacente la legge di potenza, mentre per i valori al di sotto è opportuno individuare un modello che esprima con minore incertezza l’andamento della CDF, perché la power law non modella adeguatamente la distribuzione; spesso, per questi valori bassi, migliori risultati si hanno con modelli di tipo esponenziale, log-normali o di Poisson. Nell’esempio di Moby Dick, per dire, ha senso applicare il modello power law di cui sopra solo per \\(x_{min} \\ge 26\\)   La stima di \\( x_{min} \\) può essere fatta in modo visivo, dal grafico della CDF, oppure analiticamente, in modo da avere una stima statisticamente robusta e che, soprattutto, non richieda l’intervento diretto dell’osservatore per l’interpretazione.   L’idea alla base è piuttosto semplice: scegliamo un valore \\( \\hat{x} \\) tale che renda le distribuzioni di probabilità e la migliore power law applicabile (con un dato \\( \\alpha \\)) il più simile possibile per valori sopra \\( \\hat{x} \\). Se il valore di \\( \\hat x_{min} \\) è superiore del valore vero di \\( x_{min} \\), questo implica scartare un maggior numero di osservazioni (sotto \\( x_{min} \\)) e, quindi, ottenere, una distribuzione di probabilità più scadente, per via delle fluttuazioni statistiche. D’altra parte, se il valore di \\( \\hat{x} \\) è inferiore al valore vero di \\( x_{min} \\), le distribuzioni di probabilità divergeranno per la sostanziale differenza tra i dati e il modello stesso. Il valore migliore di \\( x_{min} \\) giace all’interno di questo intervallo.   La migliore misura per quantificare la distanza tra due distribuzioni di probabilità, per dati che palesemente non seguono la distribuzione nornale, è la statistica KS (o Kolmogorof-Smirnov), ovvero la massima distanza tra le CDF dei dati e il modello:   \\[D = \\max_{x \\ge x_{min}} \\left\\lvert S(x) - P(x) \\right\\rvert\\]  con \\( S(x) \\) che rappresenta la CDF delle osservazioni per valori che siano almeno \\( x_{min} \\) e \\( P(x) \\) la CDF del modello power law che rappresenta la miglior stima possibile. La stima \\( \\hat{x} \\) di \\( x_{min} \\) è quella che minimizza \\( D \\).   Una volta individuato un soddisfacente \\( x_{min} \\), è possibile stimare un adeguato \\( \\alpha \\). Per farlo, l’approccio migliore è utilizzare il metodo della massima verosmiglianza (MLE), posto che vi sia un adeguato numero di osservazioni con \\( x \\ge x_{min} \\). LA MLE per il caso continuo è la seguente (quella per il caso discreto è molto più complessa e non verrà trattata in questa sede):   \\[\\hat{\\alpha} = 1 + n\\left[\\sum_{i=1}^n \\ln\\frac{x_i}{x_{min}}\\right] \\tag{MLE}\\]  Dove \\( \\hat{\\alpha} \\) è il valore stimato per \\( \\alpha \\), normalmente non noto, individuato da una popolazione di \\( n \\) osservazioni \\( x_i \\) con \\( i = 1, 2, \\dots, n \\), tutti tale che \\( x_i \\ge x_{min} \\).   Naturalmente, la robustezza di tali stimatori va anche essa valutata con un opportuno test per l’ipotesi, ma per essa vi chiedo di attendere il secondo articolo sull’argomento che ho in lavorazione, che riporterà degli esempi pratici in R e che toccherà anche questi temi ulteriori.   Esempi noti in letteratura   Dai ricercatori, sono stati spesso studiati e citati dei campioni che esprimono un andamento della CDF come legge di potenza. Vediamo i più famosi:           Frequenza delle parole nei testi - lo abbiamo visto con Moby Dick, ma il linguista George Kingsley Zipf ha potuto verificare come questo accada in tutta la letteratura occidentale. La trattazione è riportata in un suo elegante lavoro del 1949.            Citazioni nelle pubblicazioni scientifiche - dimostrata da Derek J. de Solla Price in un articolo su Science nel lontano 1965.       Un esempio tutto nostro: i comuni italiani   Per completare la trattazione, volevo brevemente studiare un campione che molto spesso, in letteratura, è stato assimilato ad una power law: la popolazione degli insediamenti umani in una data nazione.   Così, per essere originale, ho ben pensato di studiare il dataset dei communi italiani, messo a disposizione dall’ISTAT a valle dell’ultimo censimento nazionale. Si tratta di un dataset di 7978 comuni italiani con una popolazione compresa tra 30 e 2873494 abitanti.   Il valore del più piccolo comune d’Italia,  (30, si tratta del comune di Moncenisio, in provincia di Torino) mi ha fatto subito sospettare che la parte sinistra della distribuzione avesse un comportamento singolare (difficile pensare che ci siano più comuni di 30 abitanti rispetto agli altri).   Prima, però, di stimare un \\( x_{min} \\) per la CDF, mi sono chiesto se la distribuzione, una volta applicato il binning logaritmico, non potesse assumere una forma canonica. Così, dopo aver segmentato la popolazione in 100 intervalli ho ottenuto questo plot della densità e della percentuale di osservazioni.      Ebbene, questo grafico mi ha subito dato la sensazione di un andamento che segue una distribuzione log-normale, con una leggera distonia sulla “coda” destra che può essere imputabile a un andamento secondo la legge di potenza.   Il prossimo passo è stato, perciò, quello di individuare, attraverso il metodo di massima verosimiglianza spiegato sopra, due modelli, uno di tipo power law e uno di tipo log-normale. L’ho fatto, naturalmente, sulla CDF e ho ottenuto il seguente:      Ebbene, come previsto il modello log-normale (in verde) riesce a descrivere il campione per gran parte del suo codominio (ha \\( x_{min_1} = 430\\), fino a \\( x_{min_2} = 99469\\), al di sopra del quale è la legge di potenza (in rosso) caratterizzata dal parametro \\( \\alpha = 2.41 \\) a descrivere meglio la curva di distribuzione della CDF.   Poiché, per ciò che avevamo ipotizzato sui dati, lo studio della funzione non è interessante per valori inferiori di \\( x_{min_1} \\), il fitting si può arrestare qui. Ciò che bisognerebbe fare per terminare il lavoro è, come dicevamo, un opportuno test per verificare la robustezza degli stimatori, ma oggettivamente, nel caso specifico l’ispezione visiva dei grafici fornisce già, con discreto margine di sicurezza, le garanzie necessarie.   Per approfondire      M. E. J. Newman, Power laws, Pareto distributions and Zipf’s law, 2006;   Aaron Clauset, Cosma Rohilla Shalizi, M. E. J. Newman, Power Laws Distributions in Empirical Data, 2009  ","categories": ["Matematica"],
        "tags": [],
        "url": "https://gabrielebaldassarre.com/legge-potenza-powerlaw/",
        "teaser": "https://gabrielebaldassarre.com/assets/images/powerlaw-teaser.jpg"
      },{
        "title": "Le caratteristiche di un mondo sorprendentemente piccolo",
        "excerpt":"```{r smallworld.setup, include = FALSE, cache = FALSE} if (!require(\"pacman\")) install.packages(\"pacman\"); invisible(library(pacman)) tryCatch({   p_load(\"tidyverse\", \"igraph\") }, warning=function(w){   stop(conditionMessage(w)) })  old.par     La scienza, certe volte, compie dei percorsi strani. Duncan Watts arrivò, con il suo relatore di dottorato Steven Strogatz, a formulare un credibile modello di reti sociali umane partendo dallo studio…dei grilli!   Nel mondo reale, in effetti, i nostri amici si conoscono, molto probabilmente, anche tra di loro; un individuo che è parte della nostra cerchia non porterà 250 nuovi individui all'interno del gruppo, ma molti di meno, in quanto gran parte di quei 250 sono già componenti del gruppo stesso.  Attenzione: una parte, non tutti.  Se così non fosse, se cioè nessuno dei nostri amici avesse delle connessioni con individui all'esterno della cerchia, o ne avesse in numero trascurabile, ci ritroveremmo con una serie di \"isole\" fittissime del tutto sconnesse le une dalle altre, o connesse in modo così sporadico dal rendere irrealistico il numero magico dei sei gradi di separazione.  Empiricamente, se gli individui che compongono una rete sociale:  * hanno la maggior parte delle proprie connessioni con membri che sono a loro volta connessi tra di loro, individuando un sottogruppo ricco di connessioni reciproche;  e, contemporaneamente  * hanno anche un piccolo, ma non trascurabile, numero di connessioni con individui all'esterno di suddetto sottogruppo, in punti anche molto lontani, che fungono da \"scorciatoie\" in grado di abbattere le distanze medie tra tutti gli individui della rete;  ebbene, ci troviamo di fronte a un mondo piccolo, ovvero a una __rete small-world__.  Il mondo è, in definitiva, formato da piccole comunità (in letteratura chiamate _clique_) in cui solo una piccola parte dei loro componenti ha contatti con l'esterno. Se si può dire che il mondo è _connesso_ per via della presenza delle clique, è però _piccolo_ per via delle occasioni di connessione tra individui collocati in punti _molto distanti_ della rete.  L'intuizione empirica è tutta qui; quello che serve adesso è un modello analitico.      Eastern Island Parade in Jael, Spain, 2017   ### Il modello Watts-Strogatz  Per costruire un solido modello scientifico sono necessari due ingredienti: un'ipotesi e un po' d'ordine.  Per ciò che concerne l'ipotesi, la possiamo costruire a partire da una definizione in termini probabilistici di ciò che abbiamo appena detto. Una possibile, che calza a pennello potrebbe essere:  _\"Una rete small-world è un grafo in cui la maggior parte dei nodi __non__ sono connessi tra di loro, ma le connessioni di un nodo qualsiasi della rete hanno elevata probabilità di essere anche connessi tra di loro e tutti i nodi siano, da qualunque punto, raggiungibile con un relativamente ridotto numero di passaggi.\"_  Per quanto riguarda l'ordine, questo comporta semplificare il problema.  Le reti sociali non sono, infatti, oggetti molto ordinati (le dinamiche che ne regolano la generazione sono molteplici) e non deve essere sembrato saggio a Duncan Watts e Steven Strogatz di tuffarsi in quella confusione. Molto meglio partire con qualcosa di controllabile.  Questo \"qualcosa\" sono le __reti ad anello__ ovvero reti estremamente regolari in cui gli \\\\( N \\\\) nodi si dispongono in, appunto, un anello e ognuno di questi ha \\\\( k \\\\) connessioni tra i nodi vicini. Qui sotto è schematizzata la più semplice rete ad anello possibile, quella in cui i nodi hanno connessioni solo con i vicini più prossimi alla loro destra e alla loro sinistra.  ```{r watts-strogatz.ring, warning = FALSE, fig.asp = 1}  par(mfrow=c(1,1))  simplest.ring.network %   mutate(r = ifelse(row_number() %% 2 == 1, r - .1, r))  l % select(x, y))   smallworld.network     La rete individuata dagli aeroporti e dalle rotte degli aerei è un’altra rete small-world molto studiata, ma che bene mette in evidenza i limiti del modello Watts-Strogatz sull’incapacità di distinguere i nodi per impportanza. È evidente, infatti, come al Chicago International Airport confluiscano centinaia se non migliaia di rotte da molti altri scali e questo ne fa innegabilmente un hub, di gran lunga più importante dei molti scali regionali dissemninati in tutti gli Stati Uniti. Questa caratteristica delle reti small-world è molto importante; basti pensare alle ripercussioni che si avrebbe sull’intero traffico aereo se un hub dovesse essere non operativo, di gran lunga più serie di ciò che si avrebbe con uno scalo minore. Non a caso si dice che le reti small-world sono molto vulnerabili ad attacchi mirati.  ","categories": [],
        "tags": [],
        "url": "https://gabrielebaldassarre.com/reti-smallworld/",
        "teaser": "https://gabrielebaldassarre.com/assets/images/small-world-teaser.jpg"
      },{
        "title": "Le caratteristiche di un mondo sorprendentemente piccolo",
        "excerpt":"Se esiste un concetto della Social Network Analysis che è noto al grande pubblico è quello dei sei gradi di separazione, per quanto questa sia principalmente l’interpretazione letteraria di una teoria a sua volta frutto di un esperimento empirico molto contestato (l’esperimento di Milgram del 1967).   In natura, si sa, le coincidenze, se esistono, si danno la pena di non farsi trovare e il fatto che, andando a ben scavare, ci accorgiamo di essere distanti solo tre passaggi da Francesco Guccini e cinque da Isaac Newton potrebbe essere frutto del caso oppure della propensione innata della natura (e degli individui) di creare connessioni con i propri simili in punti imprevedibili della rete.   Quale che sia la causa non è importante, mentre lo sono gli effetti: il mondo è sorprendentemente piccolo.   Gruppi e sottogruppi in una rete sociale   Più precisamente, viviamo in un mondo in cui due individui qualunque sono separati, in media, da non più di una mezza dozzina di intermediari; e non importa se il primo sia in Spagna e il secondo sull’Isola di Pasqua.   Strano, vero? Eppure questo fenomeno non dovrebbe sorprendere, perché è, almeno numericamente, plausibile.   L’antropologia sociale ci insegna che un individuo è in grado di intrattenere relazioni socialmente attive con un numero di consimili che varia da 250 a 500, grazie anche all’avvento dei Social Network. Facendo due conti ed essendo anche al massimo conservativi questi sono i numeri della mia rete sociale:      \\( 250^1 = 250 \\) individui a un passo di distanza da me;   \\( 250^2 = 62.500 \\) individui a due passi di distanza da me;   \\( 250^3 = 15.625.000 \\) individui a tre passi di distanza da me.   …   È facile osservare come non ci sia nemmeno bisogno di arrivare a sei per includere l’intera umanità nella cerchia. Nonostante i due individui siano separati da migliaia di chilometri di oceani, deserti e montagne, la matematica non lascia adito a dubbi: sono vicini.   Eppure il numero magico è 6, non 3, ma nemmeno 12, 50 o 120, come si aspettava, intuitivamente e senza aver fatto troppi conti, Milgram durante il suo famoso esperimento.   Il punto è che, nelle loro relazioni, gli individui non scelgono le proprie connessioni in modo casuale, ma mantengono una certa coerenza locale.   In altri termini, la progressione matematica parte dal presupposto che ognuna delle, ipotizziamo, 250 connessioni di ognuno dei miei amici siano 250 individui distinti. Se ognuno di essi scegliesse, per i suoi 250 amici, degli individui completamente a caso potendoli pescare dall’intero genere umano, questa assunzione reggerebbe.   Ma gli esseri umani non hanno tutte queste libertà, perché sono soggetti a tanti vincoli,  sociali, geografici, di età di razza, ecc. che riducono di moltissimo le possibilità di scelta nella creazione della loro rete sociale. Che non sarà più casuale, ma imposta in modo tale da facilitare la creazione di sottogruppi per prossimità.       La scienza, certe volte, compie dei percorsi strani. Duncan Watts arrivò, con il suo relatore di dottorato Steven Strogatz, a formulare un credibile modello di reti sociali umane partendo dallo studio…dei grilli!   Nel mondo reale, in effetti, i nostri amici si conoscono, molto probabilmente, anche tra di loro; un individuo che è parte della nostra cerchia non porterà 250 nuovi individui all’interno del gruppo, ma molti di meno, in quanto gran parte di quei 250 sono già componenti del gruppo stesso.   Attenzione: una parte, non tutti.   Se così non fosse, se cioè nessuno dei nostri amici avesse delle connessioni con individui all’esterno della cerchia, o ne avesse in numero trascurabile, ci ritroveremmo con una serie di “isole” fittissime del tutto sconnesse le une dalle altre, o connesse in modo così sporadico dal rendere irrealistico il numero magico dei sei gradi di separazione.   Empiricamente, se gli individui che compongono una rete sociale:      hanno la maggior parte delle proprie connessioni con membri che sono a loro volta connessi tra di loro, individuando un sottogruppo ricco di connessioni reciproche;   e, contemporaneamente      hanno anche un piccolo, ma non trascurabile, numero di connessioni con individui all’esterno di suddetto sottogruppo, in punti anche molto lontani, che fungono da “scorciatoie” in grado di abbattere le distanze medie tra tutti gli individui della rete;   ebbene, ci troviamo di fronte a un mondo piccolo, ovvero a una rete small-world.   Il mondo è, in definitiva, formato da piccole comunità (in letteratura chiamate clique) in cui solo una piccola parte dei loro componenti ha contatti con l’esterno. Se si può dire che il mondo è connesso per via della presenza delle clique, è però piccolo per via delle occasioni di connessione tra individui collocati in punti molto distanti della rete.   L’intuizione empirica è tutta qui; quello che serve adesso è un modello analitico.       Eastern Island Parade in Jael, Spain, 2017   Il modello Watts-Strogatz   Per costruire un solido modello scientifico sono necessari due ingredienti: un’ipotesi e un po’ d’ordine.   Per ciò che concerne l’ipotesi, la possiamo costruire a partire da una definizione in termini probabilistici di ciò che abbiamo appena detto. Una possibile, che calza a pennello potrebbe essere:   “Una rete small-world è un grafo in cui la maggior parte dei nodi non sono connessi tra di loro, ma le connessioni di un nodo qualsiasi della rete hanno elevata probabilità di essere anche connessi tra di loro e tutti i nodi siano, da qualunque punto, raggiungibile con un relativamente ridotto numero di passaggi.”   Per quanto riguarda l’ordine, questo comporta semplificare il problema.   Le reti sociali non sono, infatti, oggetti molto ordinati (le dinamiche che ne regolano la generazione sono molteplici) e non deve essere sembrato saggio a Duncan Watts e Steven Strogatz di tuffarsi in quella confusione. Molto meglio partire con qualcosa di controllabile.   Questo “qualcosa” sono le reti ad anello ovvero reti estremamente regolari in cui gli \\( N \\) nodi si dispongono in, appunto, un anello e ognuno di questi ha \\( k \\) connessioni tra i nodi vicini. Qui sotto è schematizzata la più semplice rete ad anello possibile, quella in cui i nodi hanno connessioni solo con i vicini più prossimi alla loro destra e alla loro sinistra.      Questa caratteristica assolve alla prima parte dell’ipotesi; resta da simulare la parte relativa alle scorciatoie. Ma quali sono, in natura, le reti nelle quali il cammino minimo medio tra due punti qualunque è il più basso possibile?   Come dimostrato empiricamente poco fa, sono quelle reti in cui la probabilità, per un nodo, di instaurare una connessione con un nodo è indipendente dalla distanza tra i due nodi stessi. Le abbiamo viste prima: sono le reti casuali.   L’intuizione di Watts &amp; Strogatz nel loro modello è stata esattamente questa: una volta costruita una rete regolare ad anello, si instaura un processo per cui, navigando tutte le \\(\\frac{nk}{2} \\) connessioni nel grafo, queste hanno una probabilità \\( p \\) di essere “sganciate” dalla loro destinazione iniziale e “riconnesse” a un nodo qualunque della rete, anche (potenzialmente) molto distante.   Se per \\( p = 0 \\) il grafo rimane inalterato, al crescere di \\( p \\) esso assume una struttura sempre più disordinata fino a culminare, con \\(p = 1 \\), in uno stato in cui la rete è assimilabile a una rete casuale (ogni segmento è stato riconnesso a una nuova destinazione).   Qui sotto è schematizzato il processo per quattro valori di \\( p \\) in reti aventi \\( n = 20 \\) e \\(k = 4 \\):      Ora, dai grafici precedenti, è facile osservare che per valori di \\( p \\) vicini a 0 è massima la coesione nei sottogruppi locali, ma il cammino minimo medio è molto alto; per valori di \\( p \\) vicini a 1, invece, il cammino minimo assume un valore assimilabile a quello di una rete casuale (quindi, molto basso), a scapito di una perdita di una coesione locale tra i nodi vicini.   Ebbene, Watts &amp; Strogatz hanno dimostrato che per un certo intervallo di valori intermedi di \\( p \\), la rete presenta entrambe le caratteristiche di una rete small-world, ovvero un cammino minimo relativamente breve e una elevata presenza di clique e sottogruppi.   Demando ad un prossimo articolo l’analisi quantitativa dei valori caratterizzanti della rete, in cui calcoleremo anche questo intervallo di valori leciti per \\( p \\).   I limiti del modello   Per quanto abbia avuto, al momento della pubblicazione, l’effetto di una bomba atomica, il modello small-world non è esente da difetti.   Rispetto al modello casuale in auge fino a quel momento (il cosiddetto modello Erdős-Renyi), il modello Watts-Strogatz ne mantiene - come abbiamo visto - la peculiarità di presentare dei cammini minimi relativamente ridotti tra tutti i nodi della rete (in media).   Ma il suo più grande limite è quello di costruire strutture in cui tutti i nodi hanno lo stesso numero \\( k \\) di connessioni, ovvero presuppone che tutti i nodi abbiano la stessa popolarità (importanza, ecc.). Il modello Erdős-Renyi, per questa grandezza, prevede una più realistica distribuzione di Poisson.   Come se non bastasse, nella realtà è facile accorgersi che nelle reti small-world ci sono praticamente sempre dei nodi privilegiati, chiamati hub, che catalizzano l’attenzione (sono più popolari, ecc.) e sono caratterizzati da un numero molto consistente di connessioni - molto più alto del valor medio. Per questi, anche la distribuzione di Poisson non è realistica.   In queste reti la distribuzione del grado (degree distribution) è, piuttosto, assimilabile a una legge di potenza. Modelli più recenti di descrizione delle reti, come il modello Barabási–Albert tengono conto di questo comportamento asimmetrico dei nodi.   D’altra parte, né il modello Erdős-Renyi né il modello Barabási–Albert simulano correttamente, al contrario del modello Watts-Strogatz, la coesione locale. Nessuno di essi, in definitiva, può considerarsi un modello reliastico per descrivere la struttura di una rete sociale, ma solo una approssimazione.       La rete individuata dagli aeroporti e dalle rotte degli aerei è un’altra rete small-world molto studiata, ma che bene mette in evidenza i limiti del modello Watts-Strogatz sull’incapacità di distinguere i nodi per impportanza. È evidente, infatti, come al Chicago International Airport confluiscano centinaia se non migliaia di rotte da molti altri scali e questo ne fa innegabilmente un hub, di gran lunga più importante dei molti scali regionali dissemninati in tutti gli Stati Uniti. Questa caratteristica delle reti small-world è molto importante; basti pensare alle ripercussioni che si avrebbe sull’intero traffico aereo se un hub dovesse essere non operativo, di gran lunga più serie di ciò che si avrebbe con uno scalo minore. Non a caso si dice che le reti small-world sono molto vulnerabili ad attacchi mirati.  ","categories": [],
        "tags": [],
        "url": "https://gabrielebaldassarre.com/reti-smallworld/",
        "teaser": "https://gabrielebaldassarre.com/assets/images/small-world-teaser.jpg"
      },{
        "title": "Sistemi classici e sistemi quantistici",
        "excerpt":"Molto banalmente, per sistema fisico si intende un sistema chiuso, nel senso che non interagisce con l’esterno, in cui le cui caratteristiche interne (ovvero il suo stato) sono predicibili con esattezza. Supponendo di avere a disposizione tutte le informazioni e la conoscenza necessari per calcolare suddetto stato, questo è deterministico e predicibile con assoluta esattezza e senza ambiguità.   Tutti gli stati possibili di un sistema (sia esso classico o quantistico) formano una astrazione matematica chiamata spazio degli stati. La differenza tra un sistema classico e uno quantistico sta proprio nella natura di tale spazio.   Sistemi classici   Supponiamo di voler modellare come sistema il lancio di una moneta (un classico, no?). Nota che stiamo modellando come sistema il lancio della moneta, non la moneta in sé (come oggetto con delle caratteristiche fisiche ben precise e che esiste in un punto ben preciso dello spazio). Come tale, questo sistema può trovarsi solo in uno dei due possibili stati:      Ad ogni lancio, otterremo solo uno dei due possibili stati, senza alcuna ambiguità. Non importa quanti lanci effettuiamo: otterremo sempre testa oppure croce. E mai un po’ testa e un po’ croce.   In un sistema classico, lo stato è sempre univocabilmente specificato. Non solo: in un sistema classico, se conosciamo lo stato conosciamo tutto del sistema, incluso il risultato della misurazione (nel caso del lancio della moneta, l’esito della misurazione/esperimento è banale: coincide con la rappresentazione dello stato interno).   E il determinismo? Il lancio della moneta non è il tipico esempio di processo aleatorio? In particolare, quello che ha eguale probabilità di presentare in uscita ognumo dei due risultati possibili?   Beh, sì. Ma solo se si considera la moneta utilizzando un modello astratto, semplificato, della realtà.   Se avessimo a disposizione, prima del lancio, tutte le informazioni sul momento della moneta, le forze a cui è soggetta, l’angolo con cui è stata lanciata, la pressione atmosferica che agisce su di essa (sto volutamente esagerando) e in linea generale tutto ciò che serve per modellare la traiettoria della moneta nello spazio, il risultato sarà un processo assolutamente deterministico. Esattamente come prevede la fisica classica.   Lo spazio degli stati di un sistema classico è, matematicamente iscrivibile a un insieme. Tale insieme può avere un numero finito (per esempio, il lancio della moneta o il lancio di un dado) o infinito di membri (per esempio, la posizione di una particella in una retta), purché sia un insieme numerabile.   In quanto insieme, valgono su di esso le regole dell’insiemistica (unione e intersezione) e la logica booleana per individuare dei sottoinsiemi mediante proposizioni.   Per esempio, nel lancio del dado (sempre inteso in senso astratto), un sottoinsieme dello spazio degli stati (formato dai sei elementi {1, 2, 3, 4, 5, 6}) può essere la proposizione “numeri pari”:   \\[P = \\{2,4,6\\}\\]  E un’altra la proposizione “tutti i numeri maggiori o uguali a tre”   \\[M = \\{3,4,5,6\\}\\]  Per la logica combinatoria, anche la seguenti proposizioni sono valide:   \\[P \\cap M = \\{4, 6\\}\\]  \\[P \\cup M = \\{2,3,4,5,6\\}\\]  Sistemi quantistici (e il ruolo della matematica)   Quando abbiamo a che fare con un sistema quantistico, praticamente tutto ciò che abbiamo appena detto su un sistema classico non vale più e ci sono, invece, altre leggi che vedremo successivamente.   Ma prima di procedere, cosa vuol dire esattamente che i sistemi quantistici presentano leggi diverse? Esistono due tipologie di sistemi fisici nell’Universo? Oppure Newton aveva torto?   Nessuna delle due. Non esistono sistemi “classici” e sistemi “quantistici” nel nostro (unico) Universo e Newton non aveva torto.   In effetti, il comportamento di un sistema quantistico è così controintuitivo che la gente è portata a dire che la meccanica quantistica è “illogica” oppure che “gli elettroni si comportano in modo strano”.   Gli elettroni non si comportano in modo strano. Gli elettroni fanno quello che gli elettroni fanno e, per tutto il XX Secolo, i fisici sperimentali hanno lavorate per dimostre, e ci sono riusciti, che è esattamente così che si comportano. La realtà è inequivocabilmente quantistica.   Molto banalmente, per noi che siamo troppo grandi e abbiamo sensi troppo lenti per essere sensibili agli effetti quantistici, la realtà che percepiamo può essere descritta, perfettamente, dalla fisica newtoniana. In altre parole, la fisica classica è una approssimazione della fisica quantistica. O ancora, per sistemi grandi e lenti come quelli con cui siamo abituati a interagire (gattini, tostapane, manuali di Dungeons&amp;Dragons e montagne), gli effetti quantistici della realtà sono trascurabili e la fisica classica può tranquillamente essere adoperata.   Se, invece, vogliamo studiare sistemi microscopici, che non a caso sono definiti sistemi a scala quantistica, come il moto di una molecola o le caratteristiche di un elettrone, gli effetti quantistici non sono più trascurabili e le leggi di Newton (di Coulomb, di Maxwell, ecc. ecc.) non bastano più.   Il problema è che i nostri sensi, e con essi il nostro cervello, non sono “ingegnerizzati” per comprendere i fenomeni a scala quantistica. Ecco perché ci sembra tutto così incomprensibile. E non è una questione di preparazione: il cervello di Feynmann non è in grado di comprendere la meccanica quantistica meglio di uno studente delle superiori.   Quello che, però, può fare chi è preparato è visualizzare i fenomeni quantistici attraverso una opportuna astrazione matematica.   Non sforzatevi di capire la meccanica quantistica con i vostri sensi. Non è possibile e arriverete a conclusioni sbagliate. Quello che bisogna fare è padroneggiare il modello matematico astratto che è in grado di descriverla.   E tanto per essere ancora più chiari: guardare i video divulgativi su YouTube con titoli tipo “Quantum Mechanics finally explained!” possono aiutare all’inizio, ma senza una trattazione rigorosa (già…matematica), non si va molto avanti.   Ma non preoccupatevi: paradossalmente, la matematica della meccanica quantistica è incredibilmente semplice. Molto più semplice di quella della meccanica classica, tanto per dire.   Ok, fatta la doverosa premessa, dicevamo che la meccanica quantistica sovverte tutto ciò che abbiamo detto sui sistemi classici. Cominciamo a enunciare il tutto, e piano piano approfondiremo singolarmente i singoli punti.      Se in un sistema quantistico conosci lo stato, non conosci tutto ciò che c’è da sapere sul sistema. In particolare, non è detto che tu sia in grado di prevedere il risultato di un esperimento.   Lo spazio degli stati di un sistema quantistico non è un insieme numerabile.   In un sistema quantistico gli stati non sono necessariamente distinguibili gli uni dagli altri in modo totalmente non ambiguo.   In un sistema quantistico, non è possibile effettuare un esperimento (una misura) che lasci il sistema imperturbato, indipendentemente da quanto gentile la misura stessa sia stata.   Niente male, eh?  ","categories": ["Meccanica Quantistica"],
        "tags": [],
        "url": "https://gabrielebaldassarre.com/sistemi-classici-quantistici/",
        "teaser": "https://gabrielebaldassarre.com/assets/images/sistemi-classici-quantistici-teaser.jpg"
      },{
        "title": "Esperimenti quantistici",
        "excerpt":"In un sistema fisico che coinvolge grandezze su scala quantistica, non importa quanto gentilmente venga effettuata una misurazione (durante un esperimento), essa inevitabilmente perturberà in qualche modo il sistema, lasciandolo in uno stato diverso da quello in cui era prima della misurazione. Questa è la prima grande differenza rispetto a un sistema classico.   Badate bene che questo non significa che la misura va necessariamente ad alterare la quantità che si sta misurando, cosa che renderebbe la misura stessa inutile e il sistema non osservabile, ma di sicuro qualcosa viene alterato. Il suo stato interno, per la precisione, che impatterà molto probabilmente altre grandezze del sistema.   Vediamo bene cosa questo comporti nella pratica.   Esperimenti quantistici   Intanto diciamo che effettuare un esperimento quantistico significa misurare, con uno strumento opportuno, una particolare grandezza di un sistema (su scala) quantistica.   Abbiamo giù detto che, quando si misura una grandezza quantistica, dobbiamo considerare l’apparato di misurazione come parte integrante del sistema, un qualcosa in grado di influenzarlo. Non ci interessa, per ora, come questo apparato sia fisicamente realizzato, quindi concettuializziamolo come una black box dotata di una finestrella dalla quale è possibile leggere i risultati e di una sonda per misurare il valore della grandezza da osservare. Questo apparato, inoltre, ha un’orientazione nello spazio: un lato è chiaramente indicato come “Alto”, come gli scatoloni dei mobili Ikea.   Riprendiamo l’esempio del sistema della moneta, che può assumere i due soli valori misurati “Testa” o “Croce” e supponiamo che sia una grandezza quantistica. Supponiamo di chiamarla spin e indichiamola con la dicitura \\(\\sigma_z\\). Invece che “Testa” o “Croce”, i risultati possibili per questa grandezza sono +1 e -1, corrispondenti rispettivamente agli stati “up” e “down”.   In pratica, abbiamo la situazione seguente:      Notiamo che prima di aver eseguito la misurazione, la finestrella dell’apparato non mostra alcun valore misurato.   Supponiamo, ora, che lo spin sia stato preparato da qualcuno (o qualcosa) nello stato up. Non ci interessa sapere chi o cosa ha imposto questo stato al sistema, nella nostra concettualizzazione matematica. Ciò che importa è che lo spin sia nello stato up senza alcuna possibilità di errore. Effettuiamo la misurazione: l’apparato restituirà il valore +1.      Per essere sicuri, resettiamo l’apparato di misura e rieseguiamo le misure più volte, assicurandoci che tra una misura e l’altra non accada qualcosa nel sistema tale da alterare il valore di \\(\\sigma_z\\) (in fisica si dice che non accade niente di interessante al sistema). Otterremo sempre +1: il risultato dell’esperimento non varia.   E questa è già una prima, grande, scoperta: nei sistemi quantistici, i risultati degli esperimenti ripetuti sono confermati. La meccanica quantistica, insomma, è strana, ma non è così strana.   Adesso, facciamo qualcosa di veramente inaspettato: ruotiamo di 180° l’apparato ed eseguiamo la misurazione. Il risultato che otteniamo è -1 e tale risultato è, come prima, tale misura è confermata rieseguendo gli esperimenti.      E questa è la seconda grande scoperta: c’è, nello stato delle grandezze quantistiche, un qualche tipo di concetto di direzionalità. E, quale strumento migliore abbiamo a disposizione per descrivere, in un modello, la direzionalità se non tramite i vettori?.   Se, infatti, lo stato dello spin fosse rappresentato da un vettore con modulo unitario e che, nel caso specifico, punta verso l’alto (da cui, beh, _up__), non c’è nulla di imprevedibile nei risultati +1 e -1, in base a come è ruotato l’apparato. Newton è salvo.   Ma cosa succede se ruotiamo l’apparato di lato ed effettuiamo la misurazione? In base alla meccanica classica, dovremmo avere come risultato 0 (la componente sull’asse x del vettore up è zero). E invece…      Per quanto ci ostiniamo a misurare, il risultato sarà ancora una volta +1 oppure -1!   Non solo: è impossibile prevedere se il risultato sarà +1 o -1. Entrambi i valori hanno uguale probabilità di presentarsi, ma una volta determinato, il valore misurato viene mantenuto nelle misurazioni successive. La proprietà di conferma delle misure non è andata perduta: l’aleatorietà si presenta solo alla prima misurazione.   E se ruotiamo l’apparato di un angolo arbitrario? La meccanica classica ci dice che il risultato dovrebbe essere \\(\\cos(\\theta)\\), dove \\(\\theta\\) è l’angolo formato dall’apparato con il vettore di spin, perché tale è la componente del vettore di spin lungo la direzione in cui è orientato l’apparato. Ma niente da fare…      Il risultato è ancora una volta +1 o -1, con la stessa irritante aleatorietà iniziale.   E tanto per complicare ancora di più le cose, se riportiamo l’apparato nella posizione iniziale e tentiamo di misurare \\(\\sigma_z\\), il risultato è ancora una volta +1 o -1, con uguale probabilità. Quindi, questo vuol dire che il sistema non si trova più nello stato up, perché se così fosse il risultato della misurazione non sarebbe aleatorio (e valere, nel nostro esempio, +1). In effetti, a voler essere precisi, la figura sopra è imprecisa: la “freccia” non è più rivolta verso l’alto.   Da questo esperimento possiamo trarre due importanti conclusioni:      Lo spin può assumere solo valori discreti, ma solo per alcuni stati del sistema (es. up o down), le misure sono determinabili in modo non ambiguo. In generale, riscontreremo sempre una certa aleatorietà nelle misurazioni, il che ci suggerisce che, in un sistema quantistico, stati e misure non sono la stessa cosa. In un sistema classico questo non avviene: se si conosce lo stato di un sistema, è possibile sempre misurare le sue grandezze in modo non ambiguo.   L’atto della misurazione ha perturbato il sistema. Nello specifico, la misura di \\(\\sigma_x\\) ha distrutto qualunque informazione sulla misura di \\(\\sigma_z\\) che avevamo raccolto in precedenza. Ne consegue che le due componenti spaziali dello spin non possono essere misurate contemporaneamente o, più in generale, di un sistema quantistico non è possibile conoscere tutto, a differenza di un sistema classico.   Questi due principi (quantizzazione e indeterminazione) rappresentano i pilastri della meccanica quantistica; adesso non ci resta che costruire un modello matematico per poterla applicare.   Prima, però, facciamo pace con la fisica classica.  ","categories": ["Meccanica Quantistica"],
        "tags": [],
        "url": "https://gabrielebaldassarre.com/esperimenti-quantistici/",
        "teaser": "https://gabrielebaldassarre.com/assets/images/spazi-vettoriali-teaser.jpg"
      },{
        "title": "Esperimenti ripetuti e preparazione di un sistema",
        "excerpt":"Abbiamo detto che un esperimento in un sistema quantistico, il cui stato è modellabile con un vettore dotato di modulo,  direzione e verso, la misurazione di una grandezza, per esempio la componente dello spin lungo una certa direzione \\(\\sigma\\) , ci restituirà, ostinatamente, solo valori di +1 o -1, peraltro in modo imprevedibile.   A parte che abbiamo irrimediabilmente perduto il determinismo delle meccanica classica, il vettore di stato di \\(\\sigma\\) deve essere un vettore ben strano.   In realtà non è il vettore a essere strano, è il sistema (tanto per cambiare) a esserlo. In particolare, un sistema quantistico può trovarsi contemporaneamente in una sovrapposizione di stati (“un po’ testa e un po’ croce”). Ma di questo ci occuperemo più avanti.   In questo breve articolo faremo, invece, pace con la fisica classica. La fisica classica, lo abbiamo già detto, non è sbagliata. È solo un po’ imprecisa.   Distribuzione dei risultati di esperimenti ripetuti   Abbiamo detto che gli esperimenti fisici in meccanica quantistica sono confermabili.   Supponiamo di misurare una grandezza legata a un oggetto di scala quantistica, per esempio uno spin che sappiamo essere nello stato di up. Qualcuno o qualcosa, non importa cosa, lo ha preparato per noi in questo stato; per adesso ci basta sapere questo. Effettuiamo una misurazione con un apparato sdraiato su di un lato, ovvero misuriamo la componente \\(\\sigma_x\\) di suddetto spin sull’asse \\(x\\).   Secondo le leggi della meccanica classica, avremmo dovuto misurare un valore di zero. E, invece, misuriamo un valore di +1 o -1, in modo del tutto imprevedibile.   Se continuiamo a misurare, per la confermabilità degli esperimenti, continueremo a ottenere lo stesso valore misurato. Se la prima volta avevamo misurato +1, misureremo sempre +1. Se la prima volta abbiamo misurato -1, questo è il valore che continueremo incessantemente a misurare.   Supponiamo ora di avere non uno, ma una collezione intera di spin indipendenti tra di loro, tutti preparati nello stato up, e misuriamo \\(\\sigma_x\\). Cosa otteniamo?   Ancora una volta, una serie di +1 e di -1 (uno per ogni spin della collezione). Ma con una particolarità: la media di tutti i valori misurati sarà 0, in perfetto accordo con la meccanica classica.   Ripetiamo, ora, l’esperimento orientando l’apparato in una direzione arbitraria che formi un angolo \\(\\theta\\) con l’asse \\(z\\) (l’asse lungo up, per intenderci).   Tanto per cambiare, otteniamo una serie di valori misurati di +1 e -1, con la media dei valori misurati di \\(\\cos(\\theta)\\), nuovamente in accordo con la meccanica classica.   Quindi, sì, in un sistema quantistico non possiamo più contare sul determinismo dei valori misurati, ma le grandezze seguono una distribuzione statistica che è coerente con i risultati ottenibili applicando le leggi della meccanica classica.   Ci sono diverse interpretazioni per cui la Meccanica Quantistica sia, sembrerebbe, non deterministica. Einstein, ad esempio, era convinto di una certa incompletezza nella teoria e che ci fossero delle variabili nascoste del sistema che, una volta scoperte e considerate avrebbero portato a formulare equazioni perfettamente deterministiche.   L’interpretazione oggi, però, universalmente più accettata è che la teoria sia completa e che il suo indeterminismo riflette quello del tessuto stesso della realtà. La teoria ci permette di conoscere tutto ciò e solo ciò che è possibile conoscere di un sistema, che è ben lungi (ma non casualmente) dall’essere la totalità dell’informazione contenuta in esso, come invece accade per i sistemi classici.   Ma come si dice: piuttosto che niente, è meglio il piuttosto.   Preparare un sistema quantistico   Adesso vi chiedo un po’ di elasticità logica.   Fino ad ora abbiamo detto che qualcuno o qualcosa aveva preparato per noi il sistema (costruito da un singolo spin) in uno stato ben preciso, lo stato up, senza però dirci in quale stato lo aveva lasciato. La misura, perfettamente priva di ambiguità, della componente \\(\\sigma_z\\) ci ha consentito di conoscere tale stato, che esperimenti successivi hanno confermato. Misurare ripetutamente \\(\\sigma_z = +1\\), dopotutto, è sufficiente per affermare che lo stato dello spin sia up.   D’altra parte, anche una misura dela componente generica \\(\\sigma_\\theta\\) ottenuta con l’apparato ruotato di un angolo \\(\\theta\\) ci ha fornito una misura (+1 o -1) perfettamente non ambigua, confermata da misure successive.   Ma insomma, abbiamo forzato il sistema ad assumere una certa configurazione (stato) o ci siamo limitati a misurare una grandezza?   La domanda è mal posta: poiché una misura, come abbiamo già detto, infuenza il sistema, l’una implica l’altra. Anzi, in un sistema quantistico, misurare una grandezza e preparare il sistema sono esattamente la stessa cosa.   Meglio essere più chiari con un esempio.   Supponiamo di avere uno spin e di non sapere assolutamente il suo stato. Prendiamo il nostro solito apparato, orientato in una direzione arbitraria e misuriamo la componente dello spin \\(\\sigma_\\theta\\) lungo quella direzione. Supponiamo di leggere +1.   Sappiamo che altri valori (diversi da +1 o -1) non sono possibili. E, d’altra parte, i singoli valori misurati sono grandezze reali, non sono distribuzioni statistiche. E le misure successive, lo abbiamo detto mille volte, confermano la prima.   Questo vuol dire che il vettore di spin è orientato lungo la direzione dell’apparato (condizione sufficiente ecc. ecc.). È una coincidenza? Per una serie incredibile di circostanze, lo spin scelto rigorosamente a caso era orientato proprio nella  direzione in cui abbiamo disposto l’apparato?   Certo che no! E se proprio vogliamo essere sicuri che non sia un incredibile scherzo del destino, ruotiamo l’apparato di una manciata di gradi in una direzione arbitraria e ripetiamo l’esperimento. Otterremo, tanto per cambiare, +1 o -1.   La misurazione lungo \\(\\sigma_\\theta\\) ha preparato il sistema in uno stato, ovvero ha lasciato il sistema in uno stato corrispondente al valore misurato osservato, diverso, in generale, dallo stato in cui lo ha trovato.   Non importa cosa avevamo prima; non possiamo saperlo, dato che è lo stato che il sistema aveva prima della misura. Quello che importa è ciò che abbiamo adesso, con il sistema che si trova in un nuovo stato. Quello corrispondente al valore misurato in uscita.   A questo punto è necessario introdurre il concetto di spazio degli stati per poter costruire un modello di tutte le condizioni possibili in cui può trovarsi un sistema e vedere che relazioni ci sono con le uscite (i valori misurati).   E da qui in poi, si comincia con la matematica.  ","categories": ["Meccanica Quantistica"],
        "tags": [],
        "url": "https://gabrielebaldassarre.com/esperimenti-quantistici-distribuzione/",
        "teaser": "https://gabrielebaldassarre.com/assets/images/esperimento-laser-teaser.jpg"
      },{
        "title": "Logica classica e logica quantistica",
        "excerpt":"Lo spazio degli stati di un sistema classico è rappresentato dai componenti di un insieme. Lo spazio degli stati del sistema lancio della moneta, ad esempio, è costituito dai due elementi {Testa, Croce}, che rappresentano anche i due unici, possibili, valori della variabile misurata in un esperimento. Non sono possibili valori intermedi, così come il sistema non può trovarsi in una stato diverso da Testa o da Croce, in un dato momento.   La logica della teoria degli insiemi è l’arcinota logica booleana, che si basa sul concetto che una condizione di un sistema è esprimibile mediante una combinazione di proposizioni, ognuna rappresentata da una propria tabella di verità che dipende dalle caratteristiche del sistema studiato. Facciamo un esempio.   Supponiamo di avere il sistema Lancio di un dado. Questo sistema può trovarsi in uno di sei possibili stati:   \\[D = {1, 2, 3, 4, 5, 6}\\]     Una possibile proposizione potrebbe essere: “Tutti i risultati pari”, che rappresenta un sottoinsieme dell’insieme D.   \\[P = {2, 4, 6}\\]     Un’altra proposizione potrebbe essere “Tutti i risultati maggiori di tre”:   \\[T = {4, 5, 6}\\]     Logica classica   La logica formale booleana consente la combinazione di più proposizioni attraverso gli operatori insiemistici di complemento, unione e intersezione. Per esempio la proposizione “Tutti i risultati pari e maggiori di tre”, ovvero l’operazione di AND logico, può essere espresso come operazione di intersezione tra P e T, ovvero:   \\[A = P \\cap T\\]     Allo stesso modo valgono le operazioni di OR, di NOT e tutte le possibili declinazioni (NAND, XOR…). Ebbene, in un sistema classico vale la commutatività delle proposizioni. Siano A e B due proposizioni (insiemi), allora:   \\[P \\cap T  = T \\cap P\\]  Nella logica classica, non è importante l’ordine con cui sono valutare le proposizioni. La tabella di verità dell’espressione risultante sarà sempre definita in modo non ambiguo.   Logica quantistica   Quanto detto non è, invece, sempre vero in un sistema quantistico e questo per via del principio di indeterminazione. Sugli operatori unari possiamo essere abbastanza tranquilli:   \\[\\sigma_z = 1 \\implies NOT(\\sigma_z) = -1\\]  Per ciò che concerne gli operatori binari la questione è più complessa. Supponiamo di codificare due proposizioni booleane attraverso due grandezze quantistiche che, come sappiamo, possono assumere solo due valori e supponiamo che tali proposizione siano vere quando le grandezze assumono valore positivo:   \\[A: \\sigma_z = 1\\]  \\[B: \\sigma_x = 1\\]  Supponiamo che il sistema sia stato preparato nello stato di up e di voler misurare l’OR logico.   \\[A OR B = ?\\]  Supponiamo di iniziare la verifica di A. Poiché, per ipotesi, il sistema è nello stato di up, la misura di \\(\\sigma_z\\) darà come valore misurato 1, il che è sufficiente per verificare la veridicità di A e, quindi, dell’intera espressione (A OR B è vera se A oppure B sono vere). Possiamo fermarci qui.   Ripetiamo l’esperimento, verificando stavolta prima B. Poiché per ipotesi il sistema è nello stato di up, avremo un valore \\(\\sigma_x\\) che sarà il risultato di una distribuzione statistica avente il 50% di probabilità di valere 1. Quindi, la sola misura di B non è sufficiente per verificare l’espressione A OR B e bisogna verificare anche A.   Ma la misura di B ha distrutto ogni informazione relativa a \\(\\sigma_z\\), lasciando il sistema in uno stato compatibile con la misura perfettamente definita per \\(\\sigma_x\\) (che si sia ottenuto 1 o -1). Di conseguenza, \\(\\sigma_z\\) avrà il 50% di probabilità di valere 1, così come il 50% di probabilità di valere -1.   In definitiva, la proposizione \\(B OR A\\) ha il 25% di possibilità di essere falsa, mentre \\(A OR B\\) è certamente vera.   In un sistema quantistico, l’operatore OR non collega gli operandi in modo simmetrico. È la rappresentazione logica del principio di indeterminazione.   Da notare che non tutte le grandezze si comportano in questo modo. In un sistema quantistico esistono coppie di grandezze che possono essere misurate contemporaneamente, per restituire una tabella di verità di una proposizione perfettamente definita, come in un sistema classico. Queste grandezze hanno delle proprietà che possono essere desunte dalle caratteristiche del sistema, ovvero dal suo spazio degli stati.   Come vedremo, le due grandezze utilizzate in questo esempio, ovvero le componenti dello spin rispettivamente lungo la direzione z e lungo la direzione x, sono due grandezze che, per l’appunto, non possono essere misurate contemporaneamente e per le quali vige il principio di indeterminazione. Che, a sua volta, causa la componente di aleatorietà nella valutazione delle espressioni logiche.  ","categories": ["Meccanica Quantistica"],
        "tags": [],
        "url": "https://gabrielebaldassarre.com/logica-quantistica/",
        "teaser": "https://gabrielebaldassarre.com/assets/images/logica-quantistica-teaser.jpg"
      },{
        "title": "L'effetto fotoelettrico",
        "excerpt":"Agli albori della meccanica quantistica, agli inizi del XX secolo, Planck contribuì con una importante osservazione relativa alla radiazione di corpo nero, ovvero di un oggetto reale che, a temperatura \\(T\\), assorbe tutta la radiazione elettromagnetica incidente senza rifletterla (da cui, appunto, nero). Esso, secondo l’interpretazione classica e per via della conservazione dell’energia, re-irradia tutta l’energia  assorbita e, secondo Planck, lo fa in uno spettro di emissione quantizzato. In particolare, la radiazione emessa ha energia \\(h\\nu\\)., con \\(h = 6,626 \\cdot 10^{-34} J \\cdot s\\) la costante di Planck e \\(\\nu\\) la frequenza della radiazione emessa.   Einstein partì da queste considerazioni per spiegare un fenomeno già noto all’epoca (siamo nel 1905) relativo all’assorbimento di una radiazione elettromagnetica di frequenza \\(\\nu\\) da parte di un campione metallico con conseguente emissione di elettroni. L’effetto fotoelettrico, appunto.   Il fenomeno  Supponiamo, come detto, che una radiazione elettromagnetica monocromatica di frequenza \\(\\nu\\) incida su un campione metallico di temperatura \\(T\\) nel vuoto. Gli elettroni del metallo assorbiranno l’energia della radiazione elettromagnetica ed alcuni di essi ne assorbiranno abbastanza da saltar via dalla loro orbita intorno ai rispettivi nuclei atomici ed essere espulsi dal metallo. Questi elettroni in fuga possono essere rilevati da un opportuno apparato posto nelle vicinanze del metallo formato da un potenziale e un circuito in cui l’elettrone in movimento induce una corrente; in questo modo l’ energia degli elettroni emessi può essere misurata.   Andando a misurare la massima energia \\(E_m\\) degli elettroni espulsi si può osservare che dipende non dall’intensità della radiazione incidente, come ci saremmo aspettati dalla fisica classica, bensì dalla frequenza \\(\\nu\\) della radiazione stessa. Al di sotto di una frequenza di soglia \\(\\nu_0\\), inoltre, non vi è emissione alcuna di elettroni. L’intensità della radiazione influisce, invece, solo nella quantità di elettroni emessi.   La dipendenza tra la frequenza \\(\\nu\\) e l’energia \\(E_m\\) è lineare con un coefficiente pari alla costante di Planck. Più nel dettaglio, vige la relazione:   \\[E_m = h\\nu - q\\Phi\\]  con \\(q\\) la carica dell’elettrone  e \\(\\Phi\\) un potenziale (misurato in Volt) dipendente dalle caratteristiche fisiche del metallo. \\(E_m\\) rappresenta l’energia minima necessaria all’elettrone per essere espulso dal metallo e viene detto lavoro di estrazione.   Detto in altri termini, l’elettrone assorbe una energia \\(h\\nu\\) dalla radiazione elettromagnetica incidente e perde una energia \\(q\\Phi\\) per poter essere espulso dal metallo, il che risulta in una energia netta posseduta dall’elettrone emesso pari a \\(E_m\\).   Più spesso, in luogo della frequenza si utilizza una formulazione avente come termine la pulsazione e chiamata Relazione di Planck   \\[E = \\frac{h(2\\pi\\nu)}{2\\pi } = \\hbar\\omega\\]  Questo fenomeno mostra la natura quantizzata della radiazione elettromagnetica, trasferita (sarebbe più corretto dire mediata) da particelle discrete chiamate fotoni.   L’esperimento della doppia fenditura ha, successivamente, dimostrato la doppia natura (ondulatoria e corpuscolare) dei fotoni, mentre lo stesso esperimento effettuato con, ad esempio, dei raggi catodici ha consentito di stabilire che anche le particelle cosiddette di materia, come gli elettroni, hanno una doppia natura. In particolare, Louis de Broglie ipotizzò che una particella avente momento \\(p = mv\\) abbia una lunghezza d’onda di   \\[\\lambda = \\frac{h}{p} = \\frac{h}{mv}\\]  e, quindi,   \\[p = \\frac{h}{\\lambda} = \\frac{h}{2\\pi} = \\frac{\\hbar}{\\lambda} = \\frac{\\hbar}{k}\\]  con \\(k\\) il numero d’onda.   Queste relazioni, insieme alla relazione di Planck, connettono (in un sistema a scala quantistica, ovviamente) la natura ondulatoria dei fenomeni (con grandezze quali frequenza e lunghezza d’onda) con la descrizione delle particelle dal punto di vista corpuscolare (dotati di energia e momento).   È molto importante notare che la relazione esistente tra frequenza e lunghezza d’onda, chiamata relazione di dispersione, non è la stessa per tutte le particelle elementari.   Per esempio, nei fotoni si ha:   \\[\\nu = \\frac{c}{\\lambda} \\Rightarrow E = \\hbar\\omega = \\hbar(2\\pi\\nu) = \\hbar2\\pi(\\frac{c}{\\lambda}) = \\hbar ck = cp\\]  ma per gli elettroni, tanto per dire, la funzione \\(E(k)\\) è diversa. Questa proprietà è essenziale nello studio dei semiconduttori.   Le conclusioni di Einstein   In definitiva, nella radiazione elettromagnetica, l’energia non è distribuita uniformemente e con continuità sull’intero fronte d’onda, ma concentrata in singoli pacchetti discreti (o quanti) di energia - i fotoni - che interagiscono una alla volta con i singoli elettroni a cui cedono la loro energia. Questo, a patto che tale energia, ottenuta tramite la relazione di Planck, sia pari almeno al lavoro di estrazione necessario per rompere il legame elettrostatico che lega gli elettroni ai rispettivi nuclei.   Aumentando l’intensità della radiazione elettromagnetica, ovvero il numero di fotoni con la stessa lunghezza d’onda che vanno a incidere sul metallo non andrà ad aumentare l’energia cinetica degli elettroni emessi, ma il loro numero.   Se l’energia posseduta dai fotoni non è sufficiente per vincere il lavoro di estrazione, nessun elettrone è emesso dal metallo e l’effetto fotoelettrico non è osservato, indipendentemente da quanto intensta è la radiazione che lo ha illuminato.   Questo fenomeno, condermato sperimentalmente, contraddice apertamente quanto previsto dalla fisica classica attravero le equazioni di Maxwell, secondo cui l’intera onda interagisce nel suo complesso con tutti gli elettroni del metallo.   Questa diretta conseguenza della quantizzazione dell’energia, per cui fotoni ed elettroni interagiscono uno per uno, portò  Einstein a vincere il suo unico premio Nobel nel 1921.       Ironicamente, il grande fisico tedesco non vinse mai l’ambito premio per il lavoro che lo avrebbe consegnato alla storia, quello sulla Relatività Generale, ma solo per questo suo contributo che, di fatto, diede il via alla meccanica quantistica. Una teoria per alcuni aspetti della quale egli nutrì molte riserve, per non dire profonda avversione, durante tutta la sua vita.  ","categories": ["Meccanica Quantistica"],
        "tags": [],
        "url": "https://gabrielebaldassarre.com/effetto-fotoelettrico/",
        "teaser": "https://gabrielebaldassarre.com/assets/images/effetto-fotoelettrico-teaser.jpg"
      },{
        "title": "Lo spazio degli stati di un sistema quantistico",
        "excerpt":"A differenza di quanto avviene in un sistema classico, in un sistema quantistico lo spazio degli stati non è esprimibile attraverso la teoria degli insiemi (e la loro corrispondente logica combinatoria), ma per descriverlo è necessario costruire un opportuno modello matematico astratto.   A chi si avvicina per la prima volta allo studio della meccanica quantistica, l’adozione di un modello matematico apposito che descriva gli stati di un sistema è il primo scoglio da superare. Questo perché, mentre la logica insiemistica è molto intuitiva e adeguata a descrivere i sistemi macroscopici o classici - quelli che il nostro cervello è ben allenato a comprendere - quando ragioniamo su scala quantistica dobbiamo abbandonare la pretesa di poter comprendere intuitivamente i fenomeni e fidarci della matematica.   Non mi stancherò mai di ripetere che gli elettroni, e in generale tutte le particelle che agiscono su scala quantistica, non si comportano in modo strano.   Gli elettroni fanno quello che gli elettroni fanno. Ed è del tutto logico e normale (dal loro punto di vista).   Siamo noi a essere troppo grandi e troppo lenti per poterli studiare direttamente, ragion per cui abbiamo avuto bisogno di creare un modello matematico per studiarne il comportamento, mentre abbiamo avuto bisogno di un modello semplificato dell’Universo (la meccanica classica) per poter riportare i fenomeni che osserviamo direttamente a una scala che ci è più congeniale.   Ma non bisogna mai dimenticare che la realtà, è più che dimostrato, è decisamente quantistica.   Fatto questo atto di fede, andiamo al sodo.   Lo spazio vettoriale degli stati   Come detto, la teoria degli insiemi non è adatta per descrivere lo spazio degli stati di un sistema quantistico, né lo è la logica booleana. Questo sembra piuttosto assurdo, ma piaccia o meno al nostro cervello, è così che funziona realmente l’Universo.   In un sistema quantistico, lo spazio degli stati è, piuttosto, descritto come uno spazio vettoriale e la logica combinatoria tra i componenti di tale spazio è diversa dalla logica classica.   Non voglio scegliere nel dettaglio di cosa sia un vettore, do per scontato che lo sappiate già. È, però, importante segnalare che la nostra definizione di vettore va intesa in senso astratto. Non parliamo cioè, di vettori nello spazio reale (con le loro componenti {x, y, z, \\} per capirci), ma di oggetti matematici astratti, di dimensione \\(n\\) (anche infinita).   Di conseguenza, con spazio vettoriale intendiamo una collezione di oggetti matematici astratti costruiti in modo tale che le relazioni tra di essi modellino in modo adeguato le relazioni tra i componenti di un sistema quantistico.   Tanto per non farci mancare niente, non solo gli stati di un sistema quantistico sono dei vettori, ma sono anche dei vettori piuttosto interessanti: sono dei vettori generalmente complessi (nel senso che sono vettori le cui componenti sono nel dominio complesso, non che sono vettori complicati!).   La notazione di Dirac   Per descrivere un vettore di stato complesso \\(a\\) nello spazio degli stati di un sistema quantistico si utilizza la seguente notazione (introdotta da Paul Dirac):   \\[\\vert a \\rangle\\]  Questo “oggetto” prende il nome di ket del vettore \\(a\\).   Poiché si può dimostrare (non lo faremo) che lo spazio degli stati è uno spazio di Hilbert, esso è chiuso all’addizione. Se \\(a\\) e \\(b\\) sono due vettori di stato di un sistema quantistico, il vettore \\(c\\) combinazione dei due è anche esso vettore di stato del medesimo sistema.   \\[\\vert a \\rangle + \\vert b \\rangle = \\vert c \\rangle\\]  Similmente, è possibile moltiplicare un ket per uno scalare (genericamente complesso):   \\[z \\vert a \\rangle = \\vert a^\\prime \\rangle\\]  Anche le altre regole che definiscono gli spazi di Hilbert sono rispettate (esistenza di elemento neutro, commutatività, associatività, ecc.). Le riassumiamo tutte in un’unica proprietà, che lo spazio effettivamente rispetta: la linearità.   Possiamo lavorare anche con una rappresentazione più concreta dei ket, ovvero nella forma di vettori colonna, che ne esplicitano le componenti. Ad esempio, possiamo scrivere:   \\[\\vert A \\rangle = \\begin{pmatrix} \\alpha_1 \\\\\\\\ \\alpha_2 \\end{pmatrix}\\]  dove i coefficienti complessi \\(\\alpha\\) rappresentano le componenti del vettore.   Come abbiamo detto per la linearità vale per la somma:   \\[\\vert A \\rangle  + \\vert B \\rangle = \\begin{pmatrix} \\alpha_1 \\\\\\\\ \\alpha_2 \\end{pmatrix} + \\begin{pmatrix} \\beta_1 \\\\\\\\ \\beta_2 \\end{pmatrix} = \\begin{pmatrix} \\alpha_1 + \\beta_1 \\\\\\\\ \\alpha_2 + \\beta_2 \\end{pmatrix}\\]  e per la moltiplicazione per uno scalare complesso:   \\[z \\vert A \\rangle  = z\\begin{pmatrix} \\alpha_1 \\\\\\\\ \\alpha_2 \\end{pmatrix}  = \\begin{pmatrix} z\\alpha_1 \\\\\\\\ z\\alpha_2  \\end{pmatrix}\\]  Bra e Ket  Così come un numero complesso possiede il suo complesso coniugato, che corrisponde al numero originario con la parte immaginaria cambiata di segno, allo stesso modo un vettore ket possiede il suo corrispettivo avente come componenti i complessi coniugati del ket di partenza. Questo nuovo vettore è chiamato bra e si indica con:   \\[\\langle A \\vert\\]  È facile immaginare che ogni bra ha il suo ket corrispondente e viceversa. È importante, però, ricordare che bra e ket non condividono lo stesso spazio vettoriale. I bra, infatti, individuano uno spazio vettoriale distinto che prende il nome di spazio duale.   I bra godono delle stesse proprietà già viste per i ket, però bisogna fare alcune precisazioni.   Innanzitutto, senza eccessive sorprese, data la seguente relazione:   \\[\\vert A \\rangle + \\vert B \\rangle\\]  vale che   \\[\\langle A \\vert + \\langle B |\\]  Ma il corrispondente bra della relazione in ket   \\[z \\vert A \\rangle\\]  è   \\[\\langle A \\vert z^*\\]  dove \\(z^*\\) è il complesso coniugato di \\(z\\).   Nella rappresentazione delle componenti in colonna, per rendere ben evidente che i due spazi vettoriali individuati dai vettori bra e ket, i primi si rappresentano come vettori riga. In altre parole, al ket di A   \\[\\vert A \\rangle  = \\begin{pmatrix} \\alpha_1 \\\\\\\\ \\alpha_2 \\end{pmatrix}\\]  corrisponde il bra:   \\[\\langle A \\vert  = \\begin{pmatrix} \\alpha^*_1 &amp; \\alpha^*_2 \\end{pmatrix}\\]  Questa rappresentazione duale suggerisce che i bra e i ket possono essere moltiplicati insieme attraverso una operazione che è l’equivalente complesso del prodotto scalare: il prodotto interno   Prodotto interno  Il prodotto interno è l’operazione analoga al prodotto scalare, ma avviene tra un bra e un ket. Se, quindi, il prodotto scalare è tra vettori reali, il prodotto interno è tra vettori complessi, pertanto può esserne visto come una generalizzazione.   In pratica, il prodotto interno è il prodotto di un vettore per il duale (il complesso coniugato) dell’altro vettore. Si indica con una notazione “a sandwitch”:   \\[\\langle B \\vert A \\rangle\\]  Notate che i due vettori messi insieme fanno un bra-ket (“parentesi” in inglese): un modo mnemonico molto utile per non confondersi tra spazio e spazio duale!   Le regole del prodotto interno sono abbastanza facili da derivare. Per esempio, godono di linearità:   \\[\\langle B \\vert ( | A \\rangle + \\vert B \\rangle) = \\langle C \\vert A \\rangle + \\langle C \\vert B \\rangle\\]  Ma non della proprietà commutativa, ovvero in genere:   \\[\\langle B \\vert A \\rangle \\ne \\langle A \\vert B \\rangle\\]  ma vale la commutazione complessa:   \\[\\langle A \\vert B \\rangle = \\langle B \\vert A \\rangle^*\\]  In pratica, scambiare bra con ket equivale a prendere il complesso coniugato.   Supponiamo di effettuare il prodotto interno di un vettore per se stesso. Per la commutazione complessa avremo   \\[\\langle A \\vert A \\rangle = \\langle A \\vert A \\rangle^*\\]  che è un numero reale perché solo nei numeri reali il complesso coincide con il coniugato.   Inoltre,   \\[\\begin{pmatrix} \\alpha^*_1 &amp; \\alpha^*_2 \\end{pmatrix} \\begin{pmatrix} \\alpha_1 \\\\\\\\ \\alpha_2 \\end{pmatrix} = \\alpha^*_1\\alpha_1 + \\alpha^*_2\\alpha_2\\]  non solo è reale, ma è anche positivo ed è il quadrato della lunghezza del vettore. Possiamo generalizzare e dire che vettori complessi hanno lunghezza reale.   Per finire una nota sull’ortogonalità: due vettori complessi sono ortogonali se il loro prodotto interno à zero.   \\[\\langle A \\vert B \\rangle = 0\\]  L’ortogonalità si mantiene nello spazio duale.   In analogia con gli spazi reali, il massimo numero di vettori mutualmente ortogonali definisce la dimensionalità dello spazio (e la dimensione delle sue basi ortonormali, che vedremo nel prossimo articolo).  ","categories": ["Meccanica Quantistica"],
        "tags": [],
        "url": "https://gabrielebaldassarre.com/spazio-stati-quantistici/",
        "teaser": "https://gabrielebaldassarre.com/assets/images/spazi-vettoriali-teaser.jpg"
      },{
        "title": "Basi ortonormali in un sistema quantistico",
        "excerpt":"Chi ha un minimo di dimestichezza con l’algebra lineare conosce certamente il concetto di base di uno spazio vettoriale come l’insieme massimo di vettori mutuamente ortogonali che generano lo spazio stesso e ne determinano la dimensionalità.   Ebbene, non c’è nulla in algebra che restringa tale concetto al fatto che i suoi vettori siano reali e individuino, di conseguenza, uno spazio reale (magari tridimensionale). È assolutamente sensato generalizzare il concetto di base al campo complesso, per individuare l’intero spazio degli stati di un sistema quantistico. Tutti gli stati interni che il sistema può assumere, per intenderci.   Basi ortonormali di un sistema complesso   In maniera del tutto analoga a quanto si fa in un sistema reale, si cominciano a prendere dei vettori con modulo unitario che siano tutti tra di loro mutuamente ortogonali (che, nel campo complesso, significa prendere due vettori il cui prodotto interno sia uguale a zero. Essendo tutti questi vettori di modulo unitario, l’informazione interessante che portano in dote è la direzione che individuano.   Ebbene, continuando a prendere vettori (direzioni) ortogonali, si arriverà ad un punto in cui non è più possibile prendere altri preservando la condizione di mutua ortogonalità e saremo costretti a fermarci: i vettori presi fino a questo momento individueranno una base ortonormale e il loro numero la dimensionalità dello spazio.   La cosa interessante (sempre in perfetta analogia con i vettori reali) è che tutti i vettori dello spazio sono esprimibili come combinazione lineare degli elementi della base.   Ora, tecnicamente parlando, l’algebra non prevede che i vettori di base siano ortonormali (modulo unitario, ortogonali tra di loro), tuttavia per una serie infinita di ragioni, in meccanica quantistica normalmente lo sono. Per semplificare i calcoli, più che altro.   Basi ortonormali e meccanica quantistica   Supponiamo di avere una base ortonormale complessa di dimensione N. Esprimiamola in notazione di Dirac utilizzando un ket: \\(\\vert i \\rangle\\).   Tale base, per quanto detto, avrà \\(i_1 ... i_N\\) componenti ortogonali tra di loro.   Consideriamo ora un generico vettore di stato A ed esprimiamolo come combinazione lineare con i componenti del vettore di base:   \\[\\vert A \\rangle = \\sum_{i} \\alpha_i \\vert i \\rangle\\]  con gli \\(\\alpha_i\\) coefficienti complessi chiamati componenti della base.   Effettuiamo ora il prodotto interno della precedente uguaglianza per un particolare vettore della base j scelto arbitrariamente tra i vettori \\(i_N\\) della base.   \\[\\langle j \\vert A \\rangle = \\sum_{i} \\alpha_i \\langle j \\vert i \\rangle\\]  Poiché i vettori sono ortogonali tra di loro e hanno modulo unitario, l’equazione precedente vale 0 per qualsiasi coppia \\(\\vert j \\rangle \\ne \\vert i \\rangle\\) e vale 1 se \\(\\vert j \\rangle = \\vert i \\rangle\\).   La sommatoria quindi collassa a un unico termine diverso da zero:   \\[\\langle j \\vert A \\rangle = \\alpha_j\\]  Quindi le componenti di un generico vettore A sulla base ortonormale i  sono dati dal prodotto interno del vettore stesso con la base.   \\[\\vert A \\rangle = \\sum_i \\vert i \\rangle \\langle i \\vert A \\rangle\\]  Questa formulazione è essenziale per poter studiare la dinamica di un sistema, ovvero come lo stato di un sistema quantistico varia nel tempo e come è possibile studiarne l’evoluzione. Lo vedremo in uno dei prossimi articoli. Alla prossima!  ","categories": ["Meccanica Quantistica"],
        "tags": [],
        "url": "https://gabrielebaldassarre.com/basi-ortonormali/",
        "teaser": "https://gabrielebaldassarre.com/assets/images/basi-ortonormali-teaser.jpg"
      },{
        "title": "Stati di Spin",
        "excerpt":"Negli articoli precedenti, abbiamo definito lo spazio degli stati di un sistema quantistico come un sistema vettoriale composto da vettori complessi e, come tale, caratterizzato da una direzione, un modulo e un verso (anche se intesi non in senso spaziale). Abbiamo anche visto che una certa impredicibilità è tipica di un sistema quantistico e che la misura stessa, per quanto infinitamente gentile, altera (anzi, come abbiamo detto, prepara) il sistema.   Appurato che i vettori di stato predicono in modo perfettamente deterministico ciò che si può conoscere di un sistema (che, però, non è tutta l’informazione contenuta in un sistema; questo, per via del principio di indeterminazione), abbiamo tutti gli elementi per studiare un sistema concreto.   Quello più facile: uno spin singolo   Introduzione allo spin   Innanzitutto è bene fare una precisazione: quando parliamo di sistema di spin singolo parliamo proprio di uno spin, ovvero una caratteristica intrinseca delle particelle che non ha un corrispettivo nel mondo classico.   Non è quindi lo spin di un elettrone. L’elettrone è la particella subatomica che porta uno spin a spasso per l’Universo. Quindi il sistema che individuano è diverso, e più complicato, di quello (per certi versi astratto) individuato dal solo spin.   E a maggior ragione non è la componente di rotazione dell’elettrone sul proprio asse, anche se spesso si ricorre a questa analogia per meglio rappresentarlo, visto che il vettore di spin può essere visto come un momento angolare magnetico caratterizzato da tre componenti sugli assi spaziali \\({x, y, z}\\).   Lo spin fu introdotto da Pauli come un’astrazione puramente matematica per descrivere il modello delle particelle quantistiche; non fu mai pensato dallo scienziato come qualcosa di reale, sperimentalmente misurabile. Anzi, quando ne fu effettivamente misurato il valore, Pauli all’inizio non era del tutto certo che la grandezza misurata fosse proprio il suo spin.   Come dicevamo, però, in questa fase ci concentriamo sull’idea astratta di spin, e in particolare sugli stati assunti dal sistema da esso individuato, non dal motivo per cui assume certi valori e non altri, né tantomeno sulla sua natura fisica.   Gli stati di spin lungo z   Come abbiamo detto più volte, condurre una misurazione di una grandezza su un sistema (in questo caso, lo spin) attraverso un apparato A orientato lungo una determinata direzione lascia il sistema su quella direzione, giacché il valore misurato dall’apparato può assumere valori solo \\(\\pm 1\\).   Supponiamo di orientare l’apparato A lungo l’asse z e di effettuare una misurazione, per misurare la componente di spin su tale asse. Otteniamo, come ben sappiamo, \\(\\sigma_z = \\pm 1\\) con uguale probabilità.   Chiamiamo gli stati che hanno determinato tale misurazione come \\(\\vert u \\rangle\\) (up) e \\(\\vert d \\rangle\\) (down) a seconda che l’apparato ci abbia restituito +1 o -1.   Adesso orientiamo l’apparato lungo l’asse x per ottenere \\(\\sigma_x = \\pm 1\\). La misurazione ha lasciato il sistema nello stato \\(\\vert r \\rangle\\) oppure (righ, +1) \\(\\vert l \\rangle\\) (left, -1).   Infine, effettuiamo la misura lungo l’asse y. La misurazione in questo caso ha lasciato il sistema nello stato che etichettiamo \\(\\vert i \\rangle\\) (in, +1) oppure \\(\\vert o \\rangle\\) (out, -1). In e out, qui, nel senso che entrano o escono dallo schermo, per capirci.   Il fatto che lo spin possa assumere solo due valori, ci suggerisce che tutti i possibili stati di spin possono essere rappresentati da uno spazio vettoriale bidimensionale.   Attenzione! Questo non significa che il sistema-spin ammetta solo due stati, ma che presenta solo due possibili valori misurati. In meccanica quantistica, queste due informazioni non coindono.   Poiché lo spazo degli stati è bidimensionale, scegliamo due vettori qualunque, purché ortogonali, e utilizziamoli come base dello spazio. \\(\\vert u \\rangle\\) e \\(\\vert d \\rangle\\) andranno benissimo.   Consideriamo ora un generico vettore di stato \\(\\vert A \\rangle\\). Esso sarà esprimibile come combinazione lineare dei vettori della base attraverso dei coefficienti che rappresentano le componenti lungo la base stessa:   \\[\\vert A \\rangle = \\alpha_u \\vert u \\rangle + \\alpha_d \\vert d \\rangle\\]  Abbiamo visto che possiamo determinare le componenti lungo la base con l’operazione di prodotto interno del vettore di stato A con i vettori della base:   \\(\\alpha_u = \\langle A \\vert u \\rangle \\tag{*}\\) \\(\\alpha_d = \\langle A \\vert d \\rangle \\tag{**}\\)   Questi coefficienti complessi sono molto importanti perché il loro modulo al quadrato rappresenta una probabilità che, data una misura lungo la direzione della base, lo stato \\(\\vert A \\rangle\\) sia \\(\\vert u \\rangle\\) o \\(\\vert d \\rangle\\).   \\(P_u = \\alpha_u^*\\alpha_u\\) che \\(\\sigma_z = 1\\) ovvero lo spin sia sullo stato \\(\\vert u \\rangle\\)   \\(P_d = \\alpha_d^*\\alpha_d\\) che \\(\\sigma_z = -1\\) ovvero lo spin sia sullo stato \\(\\vert d \\rangle\\)   Per questo motivo i coefficienti \\(\\alpha\\) sono chiamati ampiezze di probabilità.   Recuperando (*) e (**) e ricordando che il bra corrispondente a un ket è il suo complesso coniugato:   \\[P_u = \\langle A \\vert u \\rangle \\langle u \\vert A \\rangle\\]  \\[P_d = \\langle A \\vert d \\rangle \\langle d \\vert A \\rangle\\]  Naturalmente, la somma delle probabilità di tutti gli eventi possibili è uguale a 1:   \\[P_u + P_d = 1\\]  ma questo significa che   \\[\\alpha_u^*\\alpha_u + \\alpha_d^*\\alpha_d = 1\\]  Poiché l’equazione sopra rappresenta tutti gli stati del sistema, il fatto che la loro somma sia 1 ci porta a completare la definizione di spazio degli stati.   Esso è definito in uno spazio vettoriale complesso di lunghezza unitaria. Tutti i vettori di base sono, pertanto, normalizzati. In più, i moduli al quadrato dei componenti su una base rappresentano le probabilità dei diversi risultati sperimentali ottenibili durante una misura.   La relazione di ortogonalità tra \\(\\vert u \\rangle\\) e \\(\\vert d \\rangle\\) è interessante perché significa (e si può provare sperimentalmente) che se uno spin è preparato nello stato up non può trovarsi nello stato down (\\(P_d = 0\\)) e viceversa. Stati ortogonali rappresentano stati fisici sperimentalmente distinti, senza alcuna ambiguità.   Se un apparato A orientato lungo l’asse z misura \\(\\sigma_z = 1\\), non vi è alcuna probabilità che lo stato sia \\(\\vert d \\rangle\\). Lo stato è certamente up ed esperimenti ripetuti confermano la misurazione perché \\(P_d = 0 \\Rightarrow P_u = 1\\).   Attenzione, però. Dire che i vettori di stato sono ortogonali non ha nulla a che vedere con le direzioni spaziali. Lo spazio degli stati è un concetto matematico; le direzioni up e down dello spin magnetico non sono (generalmente) ortogonali nelle direzioni spaziali anche se i vettori di stato \\(\\vert u \\rangle\\) e \\(\\vert d \\rangle\\) lo sono.   Lungo le altre direzioni   Apparentemente, \\(\\vert l \\rangle\\) e \\(\\vert r \\rangle\\), così come \\(\\vert i \\rangle\\) e \\(\\vert o \\rangle\\) sono vettori distinti che misurano componenti diverse dello spin (rispettivamente lungo l’asse x e l’asse y.). Tuttavia, abbiamo verificato che lo spazio degli stati del sistema di spin è bidimensionale, il che vuol dire che tutti gli stati sono esprimibili come combinazione lineare di due vettori di base.   Ora, supponendo di scegliere come base \\(\\vert l \\rangle\\) e \\(\\vert r \\rangle\\), quello che otterremo è perfettamente identico a quanto fatto prima per la componente z; semplicemente sceglieremmo una base ruotata di 90° rispetto alla precedente e con essa andremmo a misurare \\(\\sigma_x\\). Nulla di interessante, qui.   Quello che, invece, è interessante è esprimere, ad esempio, lo stato (preparato) \\(\\vert r \\rangle\\) in termini di \\(\\vert u \\rangle\\) e \\(\\vert d \\rangle\\):   \\[\\vert r \\rangle = \\alpha_u \\vert u \\rangle + \\alpha_d \\vert d \\rangle\\]  Se lo stato è stato effettivamente preparato in \\(\\vert r \\rangle\\) e successivamente l’apparato di misurazione viene ruotato per misurare \\(\\sigma_z\\), la probabilità che il suo spin sia up o down è la stessa e, come sappiamo, vale \\(\\frac{1}{2}\\):   \\[P_u = \\alpha_u^* \\alpha_u = \\frac{1}{2}\\]  \\[P_d = \\alpha_d^* \\alpha_d = \\frac{1}{2}\\]  Un vettore che soddisfa la precedente è (tralasciando il segno negativo di down, ininfluente):   \\[\\vert r \\rangle = \\frac{1}{\\sqrt{2}} \\vert u \\rangle + \\frac{1}{\\sqrt{2}} \\vert d \\rangle\\]  Per quanto riguarda left, analogamente se il sistema è stato preparato in \\(\\vert l \\rangle\\), le probabilità in \\(\\sigma_z\\) sono ancora pari a \\(\\frac{1}{2}\\). Poiché \\(\\vert l \\rangle\\) e \\(\\vert r \\rangle\\) sono ortogonali   \\[\\langle r \\vert l \\rangle = 0\\]  partiamo dall’espressione di \\(\\vert r \\rangle\\) per trovare \\(\\vert l \\rangle\\):   \\[\\vert l \\rangle = \\frac{1}{\\sqrt{2}} \\vert u \\rangle - \\frac{1}{\\sqrt{2}} \\vert d \\rangle\\]  Verifichiamo l’ortogonalità con il prodotto interno tra i coefficienti:   \\[\\begin{pmatrix} \\frac{1}{\\sqrt{2}} &amp; -\\frac{1}{\\sqrt{2}} \\end{pmatrix} \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\\\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix} = 0\\]  E, per finire, ripetiamo un simile ragionamento su in e out per ottenere i due stati:   \\[\\vert i \\rangle = \\frac{1}{\\sqrt{2}} \\vert u \\rangle + \\frac{i}{\\sqrt{2}} \\vert d \\rangle\\]  \\[\\vert o \\rangle = \\frac{1}{\\sqrt{2}} \\vert u \\rangle - \\frac{i}{\\sqrt{2}} \\vert d \\rangle\\]  Anche questi due vettori sono ortogonali tra di loro: le coppie che abbiamo individuato, in definitiva, rappresentanto tre basi del sistema di singolo spin. Ricordiamocelo quando, per onorare la tradizione, sceglieremo sistematicamente la coppia up, down come base, nei prossimi articoli. Alla prossima!  ","categories": ["Meccanica Quantistica"],
        "tags": [],
        "url": "https://gabrielebaldassarre.com/stati-spin/",
        "teaser": "https://gabrielebaldassarre.com/assets/images/stati-spin-teaser.jpg"
      },{
        "title": "Lo spazio degli stati",
        "excerpt":"```{r phase.setup, include = FALSE, cache = FALSE} if (!require(\"pacman\")) install.packages(\"pacman\"); invisible(library(pacman)) tryCatch({   p_load(\"tidyverse\", \"phaseR\") }, warning=function(w){   stop(conditionMessage(w)) })  ```  Supponiamo di voler studiare la dinamica di un sistema inerziale composto da un singolo punto materiale in moto nello spazio. In quanto tale, suddetto punto e soggetto alla legge del moto di Newton:  $$ ma = F $$  La dinamica di questo sistema inerziale è rappresentata dal _movimento_ del punto materiale, ovvero l'incognita è rappresentata dalla posizione del punto nel tempo:  $$ x = x(t) $$  Il che ci porta a concludere che la legge di Newton non solo è una equazione funzionale, ma è anche una equazione differenziale ordinaria di secondo ordine, perché l'incognita (la posizione) vi compare con il termine di derivata seconda (l'accelerazione, ricordando che $$ a(t) = \\ddot{x(t)}) $$). In quanto tale, risolverla analiticamente è quasi sempre molto complicato e in ogni caso dipende molto dalla complessità del sistema.  Poiché ogni soluzione dell'equazione di Newton è individuata da una coppia di vettori (e dalle rispettive condizioni iniziali di posizione $$ x_0 $$ e velocità $$ v_0 $$), l'intera dinamica del sistema è descrivibile come l'insieme di tutte le coppie ordinate _{x, v}_, che individuano uno spazio vettoriale in $$ \\mathbb{R}^3 \\times \\mathbb{R}^3 $$. Lo spazio generato da questo prodotto cartesiano descrive ogni possibile stato dinamico del sistema e prende il nome, per l'appunto, di spazio degli stati o __spazio delle fasi__.  Nel caso specifico, fissata una forza _F_ come una ben definita funzione delle condizioni iniziali e, genericamente, dal tempo _t_, ovvero _F(x, v, t)_, esiste una e una sola soluzione all'equazione di Newton che al tempo iniziale $$ t_0 $$ parte da un punto $$ {x_0, v_0} $$ dello spazio delle fasi e che determina l'evoluzione futura del sistema lungo _t_ secondo le leggi della meccanica (l'equazione differenziale del moto).  L'evoluzione del sistema altri non è che una _successione_ di punti nello spazio delle fasi o, se il sistema è continuo, una curva avente come tangente in ogni punto il vettore le cui componenti sono i due vettori _{x, v}_ al variare di _t_.  Questo consente di poter visualizzare lo spazio degli stati in un diagramma chiamato __ritratto in fase__ in cui andare a disegnare tutte le possibili _traiettorie_ del sistema (in che stato il sistema evolverà al variare di _t_) e definirne qualitativamente le peculiarità.  Ma forse è il caso di fare un esempio.  Il pendolo ideale -----------------  Innanzitutto una precisazione. Il concetto di ritratto in fase è del tutto generale e non è legato necessariamente a un sistema meccanico (descritto dalle equazioni del moto di Newton), ma può essere utilizzato su sistemi dinamici di qualsiasi natura e con un numero qualsiasi di dimensioni.  Nulla vieta, per capirci, di descrivere un sistema attraverso l'uso di _N_ variabili, anche infinite, e relative condizioni iniziali in modo da individuare uno spazio di fase in $$ \\mathbb{R}^N \\times \\mathbb{R}^N $$. Né siamo costretti a utilizzare vettori reali (in meccanica quantistica, ad esempio, [quei vettori sono complessi](/spazio-stati-quantistici/)).  Il problema, più che altro, sta nell'efficacia della _rappresentazione_ di uno spazio degli stati quando la dimensionalità del sistema dinamico cresce.  Tuttavia, in meccanica classica la dinamica è espressa dalle variabili posizionali e dai loro gradienti (più spesso si usa il _momento_ in luogo della velocità, ma la sostanza non cambia perché il momento $$ p = mv $$). Per essere pratici, useremo perciò nel nostro esempio un sistema meccanico caratterizzato da un movimento in una dimensione, così da avere un diagramma di fase facilmente visualizzabile in un piano cartesiano con la posizione sull'asse delle ascisse e il relativo gradiente sull'asse delle ordinate.  Il pendolo ideale si adatta bene allo scopo.  Supponiamo di esprimerne la posizione come l'angolo che forma con il proprio asse verticale $$ \\theta $$, quindi in uno spazio in $$ \\mathbb{R} $$, e il gradiente attraverso la velocità angolare $$ \\dot{\\theta} $$.  L'equazione che ne regola il moto armonico è le seguente:  $$ \\ddot{\\theta} = -\\frac{g}{l}sin\\theta $$  Nell'immagine in basso, possiamo vedere i vari stati che assume il pendolo, in termini di coppie di angolo $$ \\theta$$ e velocità angolare $$ \\dot{\\theta} $$, fissate delle condizioni iniziali per $$ \\theta_0 $$ e $$ \\dot{\\theta_0} $$. L'oscillazione del pendolo da destra verso sinistra (per poi tornare indietro) descrive una traiettoria di __transizioni di fase__ che nel ritratto in fase disegna una circonferenza.      Andamento nel tempo e rappresentazione di stato del pendolo ideale scelta una coppia di condizioni iniziali. Si dice ideale in quanto, nel sistema di riferimento inerziale preso in esame, si considerano nulle le forze di attrito. Il pendolo, insomma, continuerà a muoversi all’infinito di moto armonico sul piano xy.   Di fatto, note le condizioni iniziali ed i vettori che determinano le transizioni di stato al variare di _t_, possiamo prevedere l'evoluzione del sistema e quindi il suo futuro. È il concetto base del __determinismo laplaciano__, che però studieremo nel dettaglio in uno dei prossimi articoli.  Se, però, __non__ fissiamo una coppia di condizioni iniziali, i vettori di tutte le possibili transizioni di stato vanno a costruire un _campo vettoriale_ che descrive __tutti__ gli stati possibili del sistema: il ritratto in fase vero e proprio. Non offre una soluzione analitica dell'equzione differenziale che regola il moto del sistema (cosa che pure sarebbe stata possibile calcolare nell'esempio specifico del pendolo, ma che in genere è estremamente complicata), ma offre una buona vista di sintesi ed enfatizza la presenza di regioni particolari. Vediamole:  ```{r phase.portait, warning = FALSE, fig.asp = .8}  simplePendulum_flowField  <- flowField(simplePendulum,                                        xlim       = c(-7, 7),                                        ylim       = c(-5, 7),                                        parameters = 4,                                        add        = FALSE,                                        points = 20,                                        main = \"Pendolo Ideale - Ritratto in Fase\",                                        state.names = c(expression(theta), expression(dot(theta))),                                        axes=TRUE,                                        xaxt='n',                                        yaxt='n')  axis(side=2, at=c(-2*pi,-pi, 0, pi, 2*pi), labels=expression(-2*pi,  -pi, 0, pi, 2*pi)) axis(side=1, at=c(-2*pi, -3*pi/2, -pi, -pi/2, 0,  pi/2, pi,3*pi/2, 2*pi), labels=expression(-2*pi, -3*pi/2, -pi, -pi/2, 0, pi/2, pi, -3*pi/2, 2*pi))  simplePendulum_trajectory <- trajectory(simplePendulum,                                         y0 = matrix(c(0, 1, -6, 1, 5, 1, 0, 4, 0, -3, pi, 0, 0, 0), 7, 2, byrow = TRUE),                                         tlim = c(0, 10),                                         col = c(rep(\"orange\", 3), rep(\"darkblue\", 2), rep(\"red\", 2)),                                         parameters = 5)  ```  Interpretazione del diagramma -----------------------------  Le traiettorie disegnate rappresentano sette possibili evoluzioni del sistema a partire da altrettante condizioni iniziali, che, ricordiamo, sono i \"punti di partenza\" e sul diagramma sono rappresentate dai cerchietti. Si notano subito tre regioni particolari:  * Le traiettorie in __arancione__ sono caratterizzate da un gradiente di velocità angolare che a un certo punto cambia segno. È il comportamento che subito associamo a un movimento pendolare: il peso che oscilla in avanti fino ad un angolo $$ \\theta_{max} $$ (la distanza percorsa nella direzione delle ascisse $$ \\theta $$ aumenta), riducendo progressivamente la sua velocità angolare (la traiettoria curva avvicinandosi all'asse delle ascisse) per poi, quando la velocità è zero, tornare indietro. Lo stesso movimento si ha nel verso opposto e così via, con oscillazioni infinite.  * Le traiettorie in __blu__ sono caratterizzate da velocità angolari iniziali sufficienti per far girare il pendolo su se stesso (attorno al proprio vincolo). Il pendolo oscilla, perde progressivamente velocità, ma la velocità non è nulla quando $$ \\theta = 180° $$, quindi comincia a cadere nella direzione opposta, riprendendo velocità che ha il suo massimo quando $$ \\theta = 0 $$ per poi ricominciare. La velocità, infatti, non è mai nulla (la traiettoria non interseca mai l'asse delle ascisse).  * Le traiettorie in __rosso__ sono gli unici due punti di equilibrio del sistema, che si hanno quando il pendolo ha velocità angolare iniziale nulla e giace sul suo asse in posizione di riposo (con $$ \\theta = 0 $$ ma anche con $$ \\theta = 180° $$).  Il tutto si ripete con periodicità $$ 2 \\pi $$.  In definitiva dovrebbe essere chiaro il funzionamento di questa rappresentazione e come può essere utile per studiare l'evoluzione dinamica di un sistema, una volta che se ne è determinata la sua rappresentazione in termini di sistema di equazioni differenziali ordinarie.  Giacché non abbiamo risolto suddette equazioni, ne fornisce solo una vista approssimata, eppure la soluzione analitica non avrebbe evidenziato le differenti _regioni_ dinamiche del sistema in modo tanto lampante.  Certo, al crescere dell'ordine del sistema, la visualizzazione diventa complessa e inefficace, per non dire impossibile. Resta, tuttavia, uno strumento prezioso anche per visualizzare mentalmente come un sistema evolve e per spiegare come la sua dinamica è descritta da vettori in un campo. Questo concetto, tra l'altro, risulta essenziale nello studio della Meccanica Quantistica, oltre che ovviamente in Meccanica Razionale.  Prossimamente faremo qualche esempio pratico di realizzazione di ritratti di fase tramite R, visto che [esiste un package](https://cran.r-project.org/web/packages/phaseR/vignettes/my-vignette.html) semplice e intuitivo adatto allo scopo. Alla prossima! ","categories": ["Approfondimenti"],
        "tags": [],
        "url": "https://gabrielebaldassarre.com/spazio-degli-stati/",
        "teaser": "https://gabrielebaldassarre.com/assets/images/focault-pendulum-teaser.jpg"
      },{
        "title": "Lo spazio degli stati",
        "excerpt":"Supponiamo di voler studiare la dinamica di un sistema inerziale composto da un singolo punto materiale in moto nello spazio. In quanto tale, suddetto punto e soggetto alla legge del moto di Newton:   \\[ma = F\\]  La dinamica di questo sistema inerziale è rappresentata dal movimento del punto materiale, ovvero l’incognita è rappresentata dalla posizione del punto nel tempo:   \\[x = x(t)\\]  Il che ci porta a concludere che la legge di Newton non solo è una equazione funzionale, ma è anche una equazione differenziale ordinaria di secondo ordine, perché l’incognita (la posizione) vi compare con il termine di derivata seconda (l’accelerazione, ricordando che \\(a(t) = \\ddot{x(t)})\\)). In quanto tale, risolverla analiticamente è quasi sempre molto complicato e in ogni caso dipende molto dalla complessità del sistema.   Poiché ogni soluzione dell’equazione di Newton è individuata da una coppia di vettori (e dalle rispettive condizioni iniziali di posizione \\(x_0\\) e velocità \\(v_0\\)), l’intera dinamica del sistema è descrivibile come l’insieme di tutte le coppie ordinate {x, v}, che individuano uno spazio vettoriale in \\(\\mathbb{R}^3 \\times \\mathbb{R}^3\\). Lo spazio generato da questo prodotto cartesiano descrive ogni possibile stato dinamico del sistema e prende il nome, per l’appunto, di spazio degli stati o spazio delle fasi.   Nel caso specifico, fissata una forza F come una ben definita funzione delle condizioni iniziali e, genericamente, dal tempo t, ovvero F(x, v, t), esiste una e una sola soluzione all’equazione di Newton che al tempo iniziale \\(t_0\\) parte da un punto \\({x_0, v_0}\\) dello spazio delle fasi e che determina l’evoluzione futura del sistema lungo t secondo le leggi della meccanica (l’equazione differenziale del moto).   L’evoluzione del sistema altri non è che una successione di punti nello spazio delle fasi o, se il sistema è continuo, una curva avente come tangente in ogni punto il vettore le cui componenti sono i due vettori {x, v} al variare di t.   Questo consente di poter visualizzare lo spazio degli stati in un diagramma chiamato ritratto di fase in cui andare a disegnare tutte le possibili traiettorie del sistema (in che stato il sistema evolverà al variare di t) e definirne qualitativamente le peculiarità.   Ma forse è il caso di fare un esempio.   Il pendolo ideale   Innanzitutto una precisazione. Il concetto di ritratto di fase è del tutto generale e non è legato necessariamente a un sistema meccanico (descritto dalle equazioni del moto di Newton), ma può essere utilizzato su sistemi dinamici di qualsiasi natura e con un numero qualsiasi di dimensioni.   Nulla vieta, per capirci, di descrivere un sistema attraverso l’uso di N variabili, anche infinite, e relative condizioni iniziali in modo da individuare uno spazio di fase in \\(\\mathbb{R}^N \\times \\mathbb{R}^N\\). Né siamo costretti a utilizzare vettori reali (in meccanica quantistica, ad esempio, quei vettori sono complessi).   Il problema, più che altro, sta nell’efficacia della rappresentazione di uno spazio degli stati quando la dimensionalità del sistema dinamico cresce.   Tuttavia, in meccanica classica la dinamica è espressa dalle variabili posizionali e dai loro gradienti (più spesso si usa il momento in luogo della velocità, ma la sostanza non cambia perché il momento \\(p = mv\\)). Per essere pratici, useremo perciò nel nostro esempio un sistema meccanico caratterizzato da un movimento in una dimensione, così da avere un diagramma di fase facilmente visualizzabile in un piano cartesiano con la posizione sull’asse delle ascisse e il relativo gradiente sull’asse delle ordinate.   Il pendolo ideale si adatta bene allo scopo.   Supponiamo di esprimerne la posizione come l’angolo che forma con il proprio asse verticale \\(\\theta\\), quindi in uno spazio in \\(\\mathbb{R}\\), e il gradiente attraverso la velocità angolare \\(\\dot{\\theta}\\).   L’equazione che ne regola il moto armonico è le seguente:   \\[\\ddot{\\theta} = -\\frac{g}{l}sin\\theta\\]  Nell’immagine in basso, possiamo vedere i vari stati che assume il pendolo, in termini di coppie di angolo \\(\\theta\\) e velocità angolare \\(\\dot{\\theta}\\), fissate delle condizioni iniziali per \\(\\theta_0\\) e \\(\\dot{\\theta_0}\\). L’oscillazione del pendolo da destra verso sinistra (per poi tornare indietro) descrive una traiettoria di transizioni di fase che nel ritratto di fase disegna una circonferenza.       Andamento nel tempo e rappresentazione di stato del pendolo ideale scelta una coppia di condizioni iniziali. Si dice ideale in quanto, nel sistema di riferimento inerziale preso in esame, si considerano nulle le forze di attrito. Il pendolo, insomma, continuerà a muoversi all’infinito di moto armonico sul piano xy.   Di fatto, note le condizioni iniziali ed i vettori che determinano le transizioni di stato al variare di t, possiamo prevedere l’evoluzione del sistema e quindi il suo futuro. È il concetto base del determinismo laplaciano, che però studieremo nel dettaglio in uno dei prossimi articoli.   Se, però, non fissiamo una coppia di condizioni iniziali, i vettori di tutte le possibili transizioni di stato vanno a costruire un campo vettoriale che descrive tutti gli stati possibili del sistema: il ritratto di fase vero e proprio. Non offre una soluzione analitica dell’equzione differenziale che regola il moto del sistema (cosa che pure sarebbe stata possibile calcolare nell’esempio specifico del pendolo, ma che in genere è estremamente complicata), ma offre una buona vista di sintesi ed enfatizza la presenza di regioni particolari. Vediamole:      Interpretazione del diagramma   Le traiettorie disegnate rappresentano sette possibili evoluzioni del sistema a partire da altrettante condizioni iniziali, che, ricordiamo, sono i “punti di partenza” e sul diagramma sono rappresentate dai cerchietti. Si notano subito tre regioni particolari:           Le traiettorie in arancione sono caratterizzate da un gradiente di velocità angolare che a un certo punto cambia segno. È il comportamento che subito associamo a un movimento pendolare: il peso che oscilla in avanti fino ad un angolo \\(\\theta_{max}\\) (la distanza percorsa nella direzione delle ascisse \\(\\theta\\) aumenta), riducendo progressivamente la sua velocità angolare (la traiettoria curva avvicinandosi all’asse delle ascisse) per poi, quando la velocità è zero, tornare indietro. Lo stesso movimento si ha nel verso opposto e così via, con oscillazioni infinite.            Le traiettorie in blu sono caratterizzate da velocità angolari iniziali sufficienti per far girare il pendolo su se stesso (attorno al proprio vincolo). Il pendolo oscilla, perde progressivamente velocità, ma la velocità non è nulla quando \\(\\theta = 180°\\), quindi comincia a cadere nella direzione opposta, riprendendo velocità che ha il suo massimo quando \\(\\theta = 0\\) per poi ricominciare. La velocità, infatti, non è mai nulla (la traiettoria non interseca mai l’asse delle ascisse).            Le traiettorie in rosso sono gli unici due punti di equilibrio del sistema, che si hanno quando il pendolo ha velocità angolare iniziale nulla e giace sul suo asse in posizione di riposo (con \\(\\theta = 0\\) ma anche con \\(\\theta = 180°\\)).       Il tutto si ripete con periodicità \\(2 \\pi\\).   In definitiva dovrebbe essere chiaro il funzionamento di questa rappresentazione e come può essere utile per studiare l’evoluzione dinamica di un sistema, una volta che se ne è determinata la sua rappresentazione in termini di sistema di equazioni differenziali ordinarie.   Giacché non abbiamo risolto suddette equazioni, ne fornisce solo una vista approssimata, eppure la soluzione analitica non avrebbe evidenziato le differenti regioni dinamiche del sistema in modo tanto lampante.   Certo, al crescere dell’ordine del sistema, la visualizzazione diventa complessa e inefficace, per non dire impossibile. Resta, tuttavia, uno strumento prezioso anche per visualizzare mentalmente come un sistema evolve e per spiegare come la sua dinamica è descritta da vettori in un campo. Questo concetto, tra l’altro, risulta essenziale nello studio della Meccanica Quantistica, oltre che ovviamente in Meccanica Razionale.   Prossimamente faremo qualche esempio pratico di realizzazione di ritratti di fase tramite R, visto che esiste un package semplice e intuitivo adatto allo scopo. Alla prossima!  ","categories": ["Approfondimenti"],
        "tags": [],
        "url": "https://gabrielebaldassarre.com/spazio-degli-stati/",
        "teaser": "https://gabrielebaldassarre.com/assets/images/focault-pendulum-teaser.jpg"
      },{
        "title": "Il teorema dell'energia cinetica",
        "excerpt":"All’atto pratico, come l’elettromagnetismo parte dalle leggi di Maxwell, la dinamica classica parte dalle equazioni di Lagrange, che a loro volta sono semplicemente una riscrittura delle leggi di Newton in forma generale e universale, cioè che non dipende dal sistema di riferimento e di coordinate (es. cartesiane o polari), ottenibile mediante la derivazione di un’unica funzione scalare, chiamata appunto lagrangiana.   Questo aspetto, attraverso la formulazione hamiltoniana che ne deriva e che vedremo successivamente, è essenziale in meccanica quantistica perché mette in luce il formalismo algebrico della cinematica e della dinamica, formalismo utilizzato più volte nella teoria. Quindi ci tocca sbatterci un po’ la testa, temo.   Ma prima di cominciare, ci serve qualche nozione iniziale.   Partiamo da Newton   Supponiamo di avere un sistema in cui un punto materiale si muove, rispetto ad esso, di moto rettilineo uniforme. In questo sistema, più specificatamente chiamato sistema di riferimento inerziale vale la legge di Netwon che ne regola il movimento:   \\[ma = F\\]  e, più in generale con N punti materiali vale per ognuno:   \\[m_ka_k = F_k (k=1,\\dots N)\\]  Poiché l’accelerazione è la derivata seconda della posizione, ne consegue che la legge di Newton non è una equazione qualunque, ma è una equazione differenziale di secondo ordine dove l’incognita è x(t) e dove vi compare, nell’equazione anche attraverso le sue derivate:   \\[\\dot{x}(t) = \\frac{dx}{dt}(t), \\ddot{x}(t) = \\frac{d^2x}{dt^2}(t)\\]  che ci consentono di esprimere l’equazione di Newton in forma esplicitamente differenziale:   \\[\\ddot{x}(t) = \\frac{1}{m}F(x, \\dot{x}, t)\\]  Il principio di determinismo che regola la meccanica classica ci consene di scrivere che, assegnata una forza F, ogni soluzione dell’equzione di Newton è univocamente individuata dalle condizioni iniziali del sistema.   \\[x(0) = x_0, \\dot{x} = v_0\\]  ovvero la posizione e la velocità iniziale a \\(t_0\\).   Il motivo per cui Newton ritenne che il moto fosse determinato dalla posizione e dalla velocità iniziali è dovuto al fatto che l’equazione fosse descrivibile mediante sviluppo in serie e, pertanto, come soluzione di certe equazioni differenziali con particolari scelte dei dati iniziali (per i quali è anche possibile estrarre il relativo ritratto). È il teorema di Cauchy-Kowalewska, ma avrò pietà e non lo approfondiremo in questa sede. Piuttosto,c ominciamo a parlare di energia.   Il teorema dell’energia   Supponiamo di avere un sistema composto da un unico punto materiale soggetto a una forza F(x, v, t), ovvero genericamente dipendente dalla velocità, dalla posizione nello spazio e dal tempo. Il teorema dell’energia cinetica afferma che l’energia cinetica posseduta da un corpo è pari all’energia cinetica iniziale più il lavoro compiuto da una forza che agisce sul corpo stesso lungo una determinata traiettoria.   In termini meccanici, l’energia cinetica T è espressa come:   \\[T = \\frac{1}{2}mv^2 = \\frac{1}{2}mv v\\]  che, derivato rispetto al tempo,   \\[\\frac{d}{dt}\\frac{1}{2}m(v v) = 2v m\\frac{dv}{dt} = ma \\Rightarrow\\]  \\[\\dot{T} = F v \\tag{*}\\]  La detivata \\(\\dot{T}\\) dell’energia rappresenta la potenza della forza mentre la forma integrale   \\[T(t_1) - T(t_0) = \\int_{t_0}^{t_1} Fv dt \\tag{**}\\]  è il lavoro della forza.   Quindi, come volevasi dimostrare, le due forme (*) e (**), ovvero le forme differenziale e integrale dell’espressione, ci consentono di affermare che:      Il tasso di variazione dell’energia cinetica è pari alla potenza della forza;   La variazione netta dell’energia cinetica è pari al lavoro della forza.   Ovviamente stiamo assumendo che (come avviene nella stragrande maggioranza dei casi) la massa m sia costante; per la legge di Newton, la forza impressa sul corpo ne farà variare solo la velocità.   Supponiamo che sul corpo agisca una forza posizionale; non, quindi, una generica forza  \\(F(x, v, t)\\), ma una forza che dipende solo dalla posizione nello spazio in cui è applicata \\(F = F(x)\\). Poiché la foza permea, con la sua distribuzione, tutto lo spazio genera, appunto, un campo vettoriale di forze (ovvero una legge che assegna una forza meccanica ad ogni punto dello spazio).   In questa circostanza, l’integrale in (**) dipende solo dalla traiettoria seguita dal punto materiale nell’intervallo di tempo \\(t_0, t_1\\); chiamiamo questa traiettoria \\(\\gamma\\).   \\[T(t_1) - T(t_0) = \\int_{\\gamma}{F(x) dx}\\]  (perché data la funzione di movimento \\(x = x(t)\\), all’incremento infinitesimo si ha \\(dx = vdt\\)).   Se il campo di forze oltre a essere posizionale è conservativo, si dice che la funzione ammette potenziale, cioè che esiste una funzione \\(V(t)\\) tale che   \\[F = -gradV \\Rightarrow F_x = -\\frac{dV}{dx}, F_y = -\\frac{dV}{dy}, F_z = -\\frac{dV}{dz}\\]  La funzione V è chiamata energia potenziale e il campo è definito conservativo perché in queste condizioni vale la legge di conservazione dell’energia (o Teorema dell’Energia) che dice che, chiamata energia la quntità   \\[E = T + V\\]  (cioè la somma di energia cinetica e potenziale)   per un qualunque movimento \\(x = x(t)\\) soluzione dell’equazione di Newton \\(ma = F\\), si ha   \\[\\dot{E} = 0\\]  Questo è vero nella misura in cui   \\[Fv = -\\frac{dV}{dt} \\frac{dx}{dt} = -\\frac{dV}{dt} = -\\dot{V}\\]  Sostituendo nel teorema dell’energia cinetica visto a inizio paragrafo   \\[\\dot{T} = Fv \\Rightarrow \\dot{T} = -\\dot{V} \\Rightarrow\\]  \\[\\frac{d}{dt}(T + V) = 0\\]  Per come è formulato, il Teorema dell’Energia vale per forze che variano nello spazio con legge x(t) ed è, inoltre, una legge invariante. Al variare del sistema di riferimento inerziale considerato, infatti, variano le espressioni per l’energia, ma il suo gradiente complessivo è sempre identicamente nullo, così come può variare l’espressione per il lavoro, ma esso rappresenta, sempre e in ogni sistema, l’energia trasferita da un corpo a un altro attraverso l’applicazione di una forza.   Le costanti di moto   L’energia, essendo una quantità dinamica, è una funzione definita nello spazio degli stati \\(E = E(x, v)\\) e, poiché, in ogni punto dello spazio degli stati passa un unico vettore (originato dalle condizioni iniziali $$ x_0, v_0) che è soluzione dell’equazione di Newton, allora si può esplicitare la dipendenza   \\[E(t) = E(x(t), v(t))\\]  che, derivata rispetto al tempo ricordando che \\(E = T(v) + V(x)\\)   \\[\\dot{E} = \\frac{dT}{dv}a + \\frac{dV}{dx}v = mva - Fv = v(ma - F) = 0\\]  (il valore della precedente è zero perché ci muoviamo nel luogo delle soluzioni dell’equazione di Newton)   Le variabili dinamiche che godo di questa proprietà di invarianza rispetto a un movimento (in un sistema inerziale) sono dette costanti di moto. L’energia E, che mantiene inalterato il proprio valore lungo qualsiasi movimento \\(x = x(t)\\) che sono soluzioni dell’equazione di Newton è, evidentemente, una di esse.   Costanti di moto e ritratti in fase   Come abbiamo detto in un precedente articolo, il ritratto in fase “fotografa” la dinamica del sistema (x, v) a partire dalle diverse condizioni iniziali \\((x_0, v_0)\\). Questi valori iniziali, a loro volta, determinano un valore iniziale invariante di energia \\(E_0\\), tant’è che il principio di conservazione dell’energia fa riferimento proprio a questo valore iniziale di energia, ovvero   \\[E = T + V = E_0\\]  Questo significa che i movimenti nel ritratto in fase sono distribuiti in “fogli” stratificati sui diversi livelli di energia iniziale, invariante, \\(E_0\\). Per questo motivo, queste superfici sul diagramma delle fasi sono chiamate superfici di livello dell’energia.   Ora, non voglio insistere nella trattazione di argomenti di meccanica, ma questo formalismo razionale ci sarà utile in ambito hamiltoniano. Che, a sua volta, ci consente di trovare una correlazione nel corrispettivo concetto quantistico, tutt’altro che intuitivo.   Prendete, quindi, questo articolo come un ostico, ma utile, approfondimento formale per meglio capire i concetti che verranno in seguito. E possiate perdonarmi!  ","categories": ["Approfondimenti"],
        "tags": [],
        "url": "https://gabrielebaldassarre.com/teorema-energia-cinetica/",
        "teaser": "https://gabrielebaldassarre.com/assets/images/lagrange-teaser.jpg"
      }]
